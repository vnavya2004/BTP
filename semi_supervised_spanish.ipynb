{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNp9CyvI90RNEDnL/zr9Tg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnavya2004/BTP/blob/main/semi_supervised_spanish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load the XLM-RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Assuming you're using Google Colab and uploaded a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(\"Book3.csv\", encoding='latin1')\n",
        "df = df.sample(frac=1, random_state=42)  # Shuffle the dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "x8jnoYoTIzz6",
        "outputId": "aa5ab007-a7f0-4f37-cf04-6ca344cf5a41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff2e0792-a2db-49be-8bc8-84ac78b0689c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ff2e0792-a2db-49be-8bc8-84ac78b0689c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book3.csv to Book3 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PcaMTLxrI27t",
        "outputId": "a2b04ae8-ee4a-4f79-cf52-009293c111c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         ï»¿traducido  class\n",
              "0   AYUDI necesita encontrar una salida a esta tri...      1\n",
              "17  La relaciÃ³n abusiva me estÃ¡ matando.por favo...      1\n",
              "15  Helpi simplemente se tragÃ³ un puÃ±ado de mi a...      1\n",
              "1   Al ver destellos de suicidio de autoshamiento ...      1\n",
              "8   Esto suena absolutamente desagradable, egoÃ­st...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-200649c0-de55-4497-a558-5ea3f387436e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ï»¿traducido</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AYUDI necesita encontrar una salida a esta tri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>La relaciÃ³n abusiva me estÃ¡ matando.por favo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Helpi simplemente se tragÃ³ un puÃ±ado de mi a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Al ver destellos de suicidio de autoshamiento ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Esto suena absolutamente desagradable, egoÃ­st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-200649c0-de55-4497-a558-5ea3f387436e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-200649c0-de55-4497-a558-5ea3f387436e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-200649c0-de55-4497-a558-5ea3f387436e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5aa527b-e48d-4067-b68e-6f44e0dc9641\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5aa527b-e48d-4067-b68e-6f44e0dc9641')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5aa527b-e48d-4067-b68e-6f44e0dc9641 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"\\u00ef\\u00bb\\u00bftraducido\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"AYUDI necesita encontrar una salida a esta tristeza que creo que podr\\u00c3\\u00ada seguir esta noche.\",\n          \"Necesito a alguien con quien hablar, x Publicar con R Depressioni necesita ayuda.Alguien con quien hablar o ayudarme a desahogarme, algo.Me mud\\u00c3\\u00a9 a esta nueva ciudad, donde no conozco a nadie.Mi esposa y yo vinimos aqu\\u00c3\\u00ad.Ya estaba deprimido.Ella era literalmente mi mundo.Incluso ahora, cinco meses despu\\u00c3\\u00a9s de que nos separamos, estoy desesperadamente enamorado de ella y no s\\u00c3\\u00a9 qu\\u00c3\\u00a9 hacer.Pero la odio.un poco.Ella tuvo una aventura.Emocional seguro, posiblemente f\\u00c3\\u00adsico.Especialmente sin que se desarrolle, creo que fue f\\u00c3\\u00adsico.He tenido una vida bastante dif\\u00c3\\u00adcil, con un padrastro abusivo, una madre acumulada por drogas y creciendo por mi cuenta como familia de clase baja en el bienestar.Estoy bien por m\\u00c3\\u00ad mismo, pero no conozco a nadie.Siempre he sido un solitario, porque crec\\u00c3\\u00ad con un amigo.Confi\\u00c3\\u00a9 todo en \\u00c3\\u00a9l, y \\u00c3\\u00a9l era todo el apoyo que necesitaba.Solo la \\u00c3\\u00banica persona.Cuando conoc\\u00c3\\u00ad a mi esposa, me un\\u00c3\\u00ad al ej\\u00c3\\u00a9rcito y nos mudamos.Ella se convirti\\u00c3\\u00b3 en todo para m\\u00c3\\u00ad.No necesitaba otros amigos serios, ten\\u00c3\\u00ada amigos de trabajo y el amigo casual, as\\u00c3\\u00ad que cuando nos mudamos a esta nueva ciudad, una vez m\\u00c3\\u00a1s, no conoc\\u00c3\\u00ad a nadie.Sin embargo, una vez que llegamos aqu\\u00c3\\u00ad, comenzamos a crecer a distancia.Ella conoci\\u00c3\\u00b3 a este tipo, comenz\\u00c3\\u00b3 a salir con \\u00c3\\u00a9l, y eso fue todo.Comenz\\u00c3\\u00b3 a ir a citas, incluso pas\\u00c3\\u00b3 mi maldito cumplea\\u00c3\\u00b1os en una cita con \\u00c3\\u00a9l, apareciendo m\\u00c3\\u00a1s de las 5 p.m. con regalos que espec\\u00c3\\u00adficamente dije que no hab\\u00c3\\u00ada querido Fallout 4, no ten\\u00c3\\u00ada inter\\u00c3\\u00a9s en el juego y que hab\\u00c3\\u00ada rescatado la \\u00c3\\u00banica cosa que quer\\u00c3\\u00ada, que nosotrosSiempre yendo a cenar juntos, ella comi\\u00c3\\u00b3 con \\u00c3\\u00a9l.Pas\\u00c3\\u00b3 un mont\\u00c3\\u00b3n de otra mierda, finalmente romp\\u00c3\\u00ad con ella.Estaba asustado, desesperado y solo.Tom\\u00c3\\u00a9 demasiado tiempo rompiendo con ella, y ella me lastim\\u00c3\\u00b3 cada vez m\\u00c3\\u00a1s.Finalmente tuve que planificar mi propia ruptura, porque cada vez que lo intentaba anteriormente, ella me convenci\\u00c3\\u00b3 de que me quedara.C\\u00c3\\u00b3mo funcionar\\u00c3\\u00ada, etc. As\\u00c3\\u00ad que realmente planeo mi propia ruptura.No fue que un divertido fin de semana.Ahora, es meses despu\\u00c3\\u00a9s, y siento que me estoy desmoronando.He pasado esencialmente cuatro meses completamente solo.No conozco a nadie aqu\\u00c3\\u00ad.No estoy al hablar con ninguna de mi familia.Cort\\u00c3\\u00a9 lazos con ese amigo original hace a\\u00c3\\u00b1os porque tom\\u00c3\\u00b3 un mal camino en la vida y fue una influencia terrible.Simplemente no s\\u00c3\\u00a9 qu\\u00c3\\u00a9 hacer, y tengo miedo porque siento que todo se est\\u00c3\\u00a1 desmoronando.Y duele.Y tengo miedo, porque no puedo controlarme a m\\u00c3\\u00ad mismo, a mis pensamientos, ni a cualquier cosa.\",\n          \"Sin hogar en Lanot mucho m\\u00c3\\u00a1s tiempo hasta que me 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the columns for features (tweets) and labels\n",
        "tweets_column = 'ï»¿traducido'\n",
        "labels_column = 'class'\n",
        "NUM_LABELS = len(df[labels_column].unique())\n",
        "\n",
        "# Split the dataset\n",
        "labeled_df, unlabeled_df = train_test_split(df, test_size=0.6, stratify=df[labels_column])\n",
        "unlabeled_df, test_df = train_test_split(unlabeled_df, test_size=1/3, stratify=unlabeled_df[labels_column])\n",
        "\n",
        "# Tokenize and encode the data\n",
        "def encode_data(df, column):\n",
        "    encoded_data = tokenizer.batch_encode_plus(\n",
        "        df[column].tolist(),\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=256,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoded_data['input_ids']\n",
        "    attention_masks = encoded_data['attention_mask']\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "input_ids_labeled, attention_masks_labeled = encode_data(labeled_df, tweets_column)\n",
        "labels_labeled = torch.tensor(labeled_df[labels_column].values, dtype=torch.float)\n",
        "\n",
        "input_ids_unlabeled, attention_masks_unlabeled = encode_data(unlabeled_df, tweets_column)\n",
        "input_ids_test, attention_masks_test = encode_data(test_df, tweets_column)\n",
        "labels_test = torch.tensor(test_df[labels_column].values, dtype=torch.float)\n",
        "\n",
        "dataset_labeled = TensorDataset(input_ids_labeled, attention_masks_labeled, labels_labeled)\n",
        "dataset_unlabeled = TensorDataset(input_ids_unlabeled, attention_masks_unlabeled)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "# Define the XLM-RoBERTa model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=NUM_LABELS)\n",
        "\n",
        "# Set up the device for training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Set up the optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset_labeled)*epochs)\n",
        "\n",
        "# Training loop\n",
        "def binary_accuracy(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return accuracy_score(labels_flat, preds_flat)\n",
        "\n",
        "def binary_f1_score(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def binary_precision(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return precision_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def binary_recall(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return recall_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def train_model(model, dataset, optimizer, scheduler, epochs):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        loss_train_total = 0\n",
        "        progress_bar = tqdm(DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=batch_size), desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "        for batch in progress_bar:\n",
        "            model.zero_grad()\n",
        "            batch = tuple(b.to(device) for b in batch)\n",
        "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]\n",
        "            loss_train_total += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
        "\n",
        "        loss_train_avg = loss_train_total / len(dataset)\n",
        "        tqdm.write(f'\\nEpoch {epoch}')\n",
        "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "# Train the model on labeled data\n",
        "train_model(model, dataset_labeled, optimizer, scheduler, epochs)\n",
        "\n",
        "# Predict labels for unlabeled data\n",
        "model.eval()\n",
        "predicted_labels = []\n",
        "\n",
        "for batch in tqdm(DataLoader(dataset_unlabeled, batch_size=batch_size), desc='Predicting labels for unlabeled data', leave=False, disable=False):\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs[0]\n",
        "    predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "    predicted_labels.extend(predictions)\n",
        "\n",
        "predicted_labels = torch.tensor(predicted_labels)\n",
        "\n",
        "# Create a new dataset with original labeled data and newly labeled data\n",
        "combined_input_ids = torch.cat((input_ids_labeled, input_ids_unlabeled), dim=0)\n",
        "combined_attention_masks = torch.cat((attention_masks_labeled, attention_masks_unlabeled), dim=0)\n",
        "combined_labels = torch.cat((labels_labeled, predicted_labels), dim=0)\n",
        "\n",
        "dataset_combined = TensorDataset(combined_input_ids, combined_attention_masks, combined_labels)\n",
        "\n",
        "# Train the model on the combined dataset\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset_combined)*epochs)\n",
        "train_model(model, dataset_combined, optimizer, scheduler, epochs)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "model.eval()\n",
        "predictions, true_vals = [], []\n",
        "\n",
        "for batch in tqdm(DataLoader(dataset_test, batch_size=batch_size), desc='Evaluating', leave=False, disable=False):\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs[1]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = inputs['labels'].cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "    true_vals.append(label_ids)\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "test_accuracy = binary_accuracy(predictions, true_vals)\n",
        "test_f1 = binary_f1_score(predictions, true_vals)\n",
        "test_precision = binary_precision(predictions, true_vals)\n",
        "test_recall = binary_recall(predictions, true_vals)\n",
        "\n",
        "# Print out the evaluation metrics on test data\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing F1 Score: {test_f1}')\n",
        "print(f'Testing Precision: {test_precision}')\n",
        "print(f'Testing Recall: {test_recall}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7odiSCaIlVO",
        "outputId": "bd3ddd6a-b06d-454e-f529-00d10bba7c49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.2911902964115143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.2559983357787132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.11046432051807642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.08993554953485727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.0\n",
            "Testing F1 Score: 0.0\n",
            "Testing Precision: 0.0\n",
            "Testing Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}