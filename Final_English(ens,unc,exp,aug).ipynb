{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfaabe2c67da443cbaf24ed6fe72b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c30c7b6dca0c4cfdbefd7185fcf3dd49",
              "IPY_MODEL_55bcbe48c2a44adeb3f1d0c8f48a4a9d",
              "IPY_MODEL_449b3c2aa3694cfc87be0e9c80ae6eb4"
            ],
            "layout": "IPY_MODEL_b55ad1032d094451a9c0e41f1d158d57"
          }
        },
        "c30c7b6dca0c4cfdbefd7185fcf3dd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de3422766db424999c21f8a972efa36",
            "placeholder": "​",
            "style": "IPY_MODEL_d7fa657df2644f73a2aa0bb7469cc387",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "55bcbe48c2a44adeb3f1d0c8f48a4a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_618854f98f78422eb843890eab0ee54f",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aba8381fdcd242dcb2151be3a23eb06c",
            "value": 25
          }
        },
        "449b3c2aa3694cfc87be0e9c80ae6eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1da2f3f1f645d0a4a95a72f0094012",
            "placeholder": "​",
            "style": "IPY_MODEL_84b48eab091246bf95913869f4775bd8",
            "value": " 25.0/25.0 [00:00&lt;00:00, 734B/s]"
          }
        },
        "b55ad1032d094451a9c0e41f1d158d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de3422766db424999c21f8a972efa36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fa657df2644f73a2aa0bb7469cc387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618854f98f78422eb843890eab0ee54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba8381fdcd242dcb2151be3a23eb06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1da2f3f1f645d0a4a95a72f0094012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b48eab091246bf95913869f4775bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bcf974f3fcf4f0599c93c79d17c5343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d2f418d1d5f4ea5bcef75f2ffdbbc9b",
              "IPY_MODEL_135b59d9d7a0479185a0115e7c3ff219",
              "IPY_MODEL_b2820e59d06f4890a7605b94756c714b"
            ],
            "layout": "IPY_MODEL_e8b55df6161549a5ad8b2b12e5ba44e7"
          }
        },
        "4d2f418d1d5f4ea5bcef75f2ffdbbc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1830e0be8974a1596264e18a36bd095",
            "placeholder": "​",
            "style": "IPY_MODEL_fd67fb86d6754b219dc01490fbe21a27",
            "value": "config.json: 100%"
          }
        },
        "135b59d9d7a0479185a0115e7c3ff219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb1b918cb2740399828e2341ca0bd09",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5db231eb6b9749b8bfb32b294a76d570",
            "value": 615
          }
        },
        "b2820e59d06f4890a7605b94756c714b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f625556cc5d4e0c8664b7303ae43f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_964b8bed1e4a4e618f2ba6630cc12a6d",
            "value": " 615/615 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "e8b55df6161549a5ad8b2b12e5ba44e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1830e0be8974a1596264e18a36bd095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd67fb86d6754b219dc01490fbe21a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb1b918cb2740399828e2341ca0bd09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5db231eb6b9749b8bfb32b294a76d570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f625556cc5d4e0c8664b7303ae43f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964b8bed1e4a4e618f2ba6630cc12a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7582c3398ec44e6ca89ea09c0e3dfa53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddf1d076d3ee4c81b895429030f03093",
              "IPY_MODEL_d2bdb3ee6b1a44d0906500c871b99839",
              "IPY_MODEL_3c8dbfe6f9bf4f8eb49699c10f348da3"
            ],
            "layout": "IPY_MODEL_d54973b00ec945c6b196b4cd0a448778"
          }
        },
        "ddf1d076d3ee4c81b895429030f03093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facc5cb6d670473bb6145c906ec9ada7",
            "placeholder": "​",
            "style": "IPY_MODEL_c41bb9f80dd941f787bec1fa03584208",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "d2bdb3ee6b1a44d0906500c871b99839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be4361044d61431e96697d7456f7be26",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5204ba8cee6a43f2bb81f43896a61bb5",
            "value": 5069051
          }
        },
        "3c8dbfe6f9bf4f8eb49699c10f348da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62ca461248fb49d28d3142bb36174321",
            "placeholder": "​",
            "style": "IPY_MODEL_0552b616cc04443ba9f93566d25d40c2",
            "value": " 5.07M/5.07M [00:06&lt;00:00, 815kB/s]"
          }
        },
        "d54973b00ec945c6b196b4cd0a448778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facc5cb6d670473bb6145c906ec9ada7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41bb9f80dd941f787bec1fa03584208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be4361044d61431e96697d7456f7be26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5204ba8cee6a43f2bb81f43896a61bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62ca461248fb49d28d3142bb36174321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0552b616cc04443ba9f93566d25d40c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7951b16a8bef46398d98ff91585dc47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb97d2036e04bee9916763550523c50",
              "IPY_MODEL_9f973f5360a144e9a8a37684f9a6ef7a",
              "IPY_MODEL_65ca1c1a0c9946dfb841dc7d2a94d39a"
            ],
            "layout": "IPY_MODEL_a48d050dfc68406faeb6116a9f3fec8a"
          }
        },
        "beb97d2036e04bee9916763550523c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_301a16e626464fdba22e8b398f5f7ee9",
            "placeholder": "​",
            "style": "IPY_MODEL_a81f07149db64a62b59b0ff7e0ae7e9f",
            "value": "tokenizer.json: 100%"
          }
        },
        "9f973f5360a144e9a8a37684f9a6ef7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4023c213c854475bb898300703eaa928",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_035efa3e6718419684088c6ac25ffae3",
            "value": 9096718
          }
        },
        "65ca1c1a0c9946dfb841dc7d2a94d39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977a906867b444ddad6bbf7ff78dfe52",
            "placeholder": "​",
            "style": "IPY_MODEL_f8be3541b087477f8a0646bad5f43c6d",
            "value": " 9.10M/9.10M [00:08&lt;00:00, 1.07MB/s]"
          }
        },
        "a48d050dfc68406faeb6116a9f3fec8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301a16e626464fdba22e8b398f5f7ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81f07149db64a62b59b0ff7e0ae7e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4023c213c854475bb898300703eaa928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035efa3e6718419684088c6ac25ffae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "977a906867b444ddad6bbf7ff78dfe52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8be3541b087477f8a0646bad5f43c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "898bd29f65df4fae99362ec6659108b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7214d56ad4b1422fa8998800ed32431e",
              "IPY_MODEL_96174eadbab740d2ab36ad821b1ab315",
              "IPY_MODEL_431e700be60a4d949393731a4c0c0e49"
            ],
            "layout": "IPY_MODEL_218043e18c4c46679c031d273bf57d46"
          }
        },
        "7214d56ad4b1422fa8998800ed32431e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa7c7a9318f40dda5b19a4f61f06c64",
            "placeholder": "​",
            "style": "IPY_MODEL_9685045808314a34802de162021a22c5",
            "value": "model.safetensors: 100%"
          }
        },
        "96174eadbab740d2ab36ad821b1ab315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0c8aeb5665406d9ddc9a24a9c01bb5",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db2e7cd8a5854e16ac0b3988c757c251",
            "value": 1115567652
          }
        },
        "431e700be60a4d949393731a4c0c0e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e374fddec2d04b75ba044d395538e48c",
            "placeholder": "​",
            "style": "IPY_MODEL_78eabb9898bc4a3c8aeb2628dbc7a794",
            "value": " 1.12G/1.12G [00:10&lt;00:00, 188MB/s]"
          }
        },
        "218043e18c4c46679c031d273bf57d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa7c7a9318f40dda5b19a4f61f06c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9685045808314a34802de162021a22c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a0c8aeb5665406d9ddc9a24a9c01bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db2e7cd8a5854e16ac0b3988c757c251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e374fddec2d04b75ba044d395538e48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78eabb9898bc4a3c8aeb2628dbc7a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnavya2004/BTP/blob/main/Final_English(ens%2Cunc%2Cexp%2Caug).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20YMsWp1AYP",
        "outputId": "255b3847-40f1-4e68-e58f-c0aa751297f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=70e2f9324bbb25dbf2ca62f43e675f2d4395342ebeb06446a9bf95f85807350a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "# Load the XLM-RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Assuming you're using Google Colab and uploaded a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel(pd.ExcelFile(list(uploaded.keys())[0]), header=0)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "dfaabe2c67da443cbaf24ed6fe72b84b",
            "c30c7b6dca0c4cfdbefd7185fcf3dd49",
            "55bcbe48c2a44adeb3f1d0c8f48a4a9d",
            "449b3c2aa3694cfc87be0e9c80ae6eb4",
            "b55ad1032d094451a9c0e41f1d158d57",
            "5de3422766db424999c21f8a972efa36",
            "d7fa657df2644f73a2aa0bb7469cc387",
            "618854f98f78422eb843890eab0ee54f",
            "aba8381fdcd242dcb2151be3a23eb06c",
            "2b1da2f3f1f645d0a4a95a72f0094012",
            "84b48eab091246bf95913869f4775bd8",
            "8bcf974f3fcf4f0599c93c79d17c5343",
            "4d2f418d1d5f4ea5bcef75f2ffdbbc9b",
            "135b59d9d7a0479185a0115e7c3ff219",
            "b2820e59d06f4890a7605b94756c714b",
            "e8b55df6161549a5ad8b2b12e5ba44e7",
            "d1830e0be8974a1596264e18a36bd095",
            "fd67fb86d6754b219dc01490fbe21a27",
            "2eb1b918cb2740399828e2341ca0bd09",
            "5db231eb6b9749b8bfb32b294a76d570",
            "4f625556cc5d4e0c8664b7303ae43f5a",
            "964b8bed1e4a4e618f2ba6630cc12a6d",
            "7582c3398ec44e6ca89ea09c0e3dfa53",
            "ddf1d076d3ee4c81b895429030f03093",
            "d2bdb3ee6b1a44d0906500c871b99839",
            "3c8dbfe6f9bf4f8eb49699c10f348da3",
            "d54973b00ec945c6b196b4cd0a448778",
            "facc5cb6d670473bb6145c906ec9ada7",
            "c41bb9f80dd941f787bec1fa03584208",
            "be4361044d61431e96697d7456f7be26",
            "5204ba8cee6a43f2bb81f43896a61bb5",
            "62ca461248fb49d28d3142bb36174321",
            "0552b616cc04443ba9f93566d25d40c2",
            "7951b16a8bef46398d98ff91585dc47e",
            "beb97d2036e04bee9916763550523c50",
            "9f973f5360a144e9a8a37684f9a6ef7a",
            "65ca1c1a0c9946dfb841dc7d2a94d39a",
            "a48d050dfc68406faeb6116a9f3fec8a",
            "301a16e626464fdba22e8b398f5f7ee9",
            "a81f07149db64a62b59b0ff7e0ae7e9f",
            "4023c213c854475bb898300703eaa928",
            "035efa3e6718419684088c6ac25ffae3",
            "977a906867b444ddad6bbf7ff78dfe52",
            "f8be3541b087477f8a0646bad5f43c6d"
          ]
        },
        "id": "5f7NkQlT1CUe",
        "outputId": "d4f0e05e-e3a0-454e-a7b1-eb869e85d2dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfaabe2c67da443cbaf24ed6fe72b84b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bcf974f3fcf4f0599c93c79d17c5343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7582c3398ec44e6ca89ea09c0e3dfa53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7951b16a8bef46398d98ff91585dc47e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d58fc633-0b20-44fd-91ea-024e0fce6635\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d58fc633-0b20-44fd-91ea-024e0fce6635\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving newenglish.xlsx to newenglish.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Separate the dataset into two based on label 0 and label 1\n",
        "df_0 = df[df['labels'] == 0]\n",
        "df_1 = df[df['labels'] == 1]\n",
        "\n",
        "# Find the minimum count between both labels\n",
        "min_count = min(len(df_0), len(df_1))\n",
        "\n",
        "print(min_count)\n",
        "# Reduce both datasets to the minimum count\n",
        "df_0_reduced = df_0.sample(n=min_count, random_state=42)\n",
        "df_1_reduced = df_1.sample(n=min_count, random_state=42)\n",
        "\n",
        "# Concatenate both reduced datasets\n",
        "df_balanced = pd.concat([df_0_reduced, df_1_reduced])\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = df_balanced.sample(frac=0.4, random_state=42).reset_index(drop=True)\n",
        "print(df[df['labels'] == 0])\n",
        "print(df[df['labels'] == 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRXWkxh21IL1",
        "outputId": "7623a82d-198f-41fc-fb95-62483bb79340"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21953\n",
            "                                                  tweets  labels\n",
            "2                   bthats with world goingnnnnnnnnnnnnn       0\n",
            "6                    bdepression welcome back sweetheart       0\n",
            "8           goal good even better great some days rxexxa       0\n",
            "9      pleased announce that antisocial started farm ...       0\n",
            "11     quick make happy again canxexxt have depressed...       0\n",
            "...                                                  ...     ...\n",
            "17547  bonce face body cure anxiety become mentally s...       0\n",
            "17551                                          bcheerful       0\n",
            "17554  cheer when comes hospital bought donkey decidi...       0\n",
            "17558  bsome nonyankees newshearing that some washing...       0\n",
            "17561                                  fantastic pleased       0\n",
            "\n",
            "[8796 rows x 2 columns]\n",
            "                                                  tweets  labels\n",
            "0      bpeople start using substances many reasons so...       1\n",
            "1              bthe depression adds little pizazz flavor       1\n",
            "3      next from xexxs office xexxcsolitary confineme...       1\n",
            "4      ixexxm glad asked that melissa because know ch...       1\n",
            "5      band poor people depressed stuff peaches uses ...       1\n",
            "...                                                  ...     ...\n",
            "17555  blisten lads your still geezer speak about you...       1\n",
            "17556  depression isnxexxt just sadness itxexxs somet...       1\n",
            "17557  also being depressed threapistnbarely keeping ...       1\n",
            "17559  balready lady burst into tears tell afraid jok...       1\n",
            "17560  bthose shots full globe life park absolutely f...       1\n",
            "\n",
            "[8766 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tweets_column = 'tweets'\n",
        "labels_column = 'labels'\n",
        "NUM_LABELS = len(df[labels_column].unique())\n",
        "possible_labels = df[labels_column].unique()\n",
        "label_dict = {possible_label: index for index, possible_label in enumerate(possible_labels)}\n",
        "df['labels'] = df[labels_column].map(label_dict)\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize NLTK components\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "nltk.download('wordnet')  # Lemmatizer if needed\n",
        "\n",
        "# Load English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "print(stop_words)\n",
        "\n",
        "# Preprocessing function for English text\n",
        "def preprocess_english_tweet(tweet):\n",
        "    tweet = str(tweet)\n",
        "\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove special characters and digits (keeping only English letters)\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
        "\n",
        "    # Tokenize the tweet\n",
        "    words = tweet.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # You can apply stemming or lemmatization here if desired\n",
        "    words = [word for word in words]\n",
        "\n",
        "    # Join the cleaned words back into a string\n",
        "    tweet = ' '.join(words)\n",
        "\n",
        "    return tweet\n",
        "\n",
        "# Apply preprocessing to the 'tweets' column\n",
        "df[tweets_column] = df[tweets_column].astype(str).apply(preprocess_english_tweet)\n",
        "\n",
        "# Split dataset into labeled (20%), unlabeled (60%), and test (20%) sets\n",
        "df_labeled, df_temp = train_test_split(df, stratify=df[labels_column], test_size=0.8)\n",
        "df_unlabeled, df_temp_val_test = train_test_split(df_temp, stratify=df_temp[labels_column], test_size=0.25)\n",
        "df_val, df_test = train_test_split(df_temp_val_test, stratify=df_temp_val_test[labels_column], test_size=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yBUY12F1KC9",
        "outputId": "a29d7c86-51dd-4590-e720-66eddbe55092"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"wouldn't\", 'hasn', 'as', 'myself', \"shan't\", 'ourselves', 'were', 'ours', 'haven', 'some', 'am', 'how', \"that'll\", 'has', 'her', 'after', 'where', 're', 'while', 'than', 'through', \"haven't\", 'needn', 'wasn', 'why', 'that', 'does', 'hers', \"isn't\", 'himself', \"mightn't\", 'been', 'so', 'his', \"didn't\", 'is', 'further', 'on', 'or', 'in', 'mightn', 'yours', 'its', 'them', 'should', 'into', 'up', 'd', 'didn', 'o', 'don', 'to', \"you're\", 'from', 'your', 'an', \"you'll\", 'what', 'those', 'few', 'but', 'for', 'themselves', \"don't\", 'off', 'more', \"weren't\", 'theirs', 'whom', 'only', 'ma', \"you've\", 'a', 'over', 'the', 'he', 'now', 'no', 'if', 'when', 'wouldn', 'do', 'couldn', 'ain', 'him', 'of', 'between', 'aren', 'same', 'y', 'be', 'this', 'here', 'had', 'having', 'very', 'yourself', 'which', 'can', 'we', 'itself', 'most', 'own', \"needn't\", 'and', \"won't\", 'our', 'nor', 'above', 'they', 'isn', 'was', 'too', 'she', \"couldn't\", 'once', 'again', 'yourselves', 'then', 'have', 'all', 'before', 'during', 'under', \"hadn't\", \"aren't\", \"doesn't\", \"hasn't\", 'each', 'just', 'not', 'shouldn', 'll', 'herself', 'by', 'out', \"she's\", 'who', 'other', 've', 'at', 'won', 'did', 'being', 'doesn', \"wasn't\", 'any', \"shouldn't\", 'i', 'you', 'me', 'down', 'hadn', \"it's\", \"mustn't\", 'these', \"should've\", 'there', 'about', 'against', 'such', 'shan', 'because', 't', 'it', 'their', 'below', 'will', 'm', 'both', 'weren', 's', 'doing', \"you'd\", 'are', 'my', 'mustn', 'until', 'with'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the tweets and labels columns to the desired formats\n",
        "df_labeled[tweets_column] = df_labeled[tweets_column].astype(str)\n",
        "df_labeled[labels_column] = df_labeled[labels_column].map(label_dict).to_numpy()\n",
        "\n",
        "df_val[tweets_column] = df_val[tweets_column].astype(str)\n",
        "df_val[labels_column] = df_val[labels_column].map(label_dict).to_numpy()\n",
        "df_unlabeled[tweets_column] = df_unlabeled[tweets_column].astype(str)\n",
        "# Unlabeled data has no labels, so no conversion for y_unlabeled\n",
        "df_test[tweets_column] = df_test[tweets_column].astype(str)\n",
        "df_test[labels_column] = df_test[labels_column].map(label_dict).to_numpy()"
      ],
      "metadata": {
        "id": "xSHRJV8i1LS3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load translation models\n",
        "src_to_tgt_model_name = 'Helsinki-NLP/opus-mt-en-fr'  # English to French\n",
        "tgt_to_src_model_name = 'Helsinki-NLP/opus-mt-fr-en'  # French to English\n",
        "\n",
        "src_to_tgt_model = MarianMTModel.from_pretrained(src_to_tgt_model_name)\n",
        "src_to_tgt_tokenizer = MarianTokenizer.from_pretrained(src_to_tgt_model_name)\n",
        "\n",
        "tgt_to_src_model = MarianMTModel.from_pretrained(tgt_to_src_model_name)\n",
        "tgt_to_src_tokenizer = MarianTokenizer.from_pretrained(tgt_to_src_model_name)\n",
        "\n",
        "def back_translate(texts):\n",
        "    # Translate Bangla to English\n",
        "    translated = src_to_tgt_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated_texts = src_to_tgt_model.generate(**translated)\n",
        "    translated_texts = [src_to_tgt_tokenizer.decode(t, skip_special_tokens=True) for t in translated_texts]\n",
        "\n",
        "    # Translate English back to Bangla\n",
        "    back_translated = tgt_to_src_tokenizer(translated_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    back_translated_texts = tgt_to_src_model.generate(**back_translated)\n",
        "    back_translated_texts = [tgt_to_src_tokenizer.decode(t, skip_special_tokens=True) for t in back_translated_texts]\n",
        "\n",
        "    return back_translated_texts\n",
        "# Generate back-translated samples for labeled data\n",
        "def augment_data_with_back_translation(df_labeled, augmentation_factor=1):\n",
        "    augmented_samples = []\n",
        "\n",
        "    for _ in range(augmentation_factor):\n",
        "        # Back-translate the tweets\n",
        "        back_translated_texts = back_translate(df_labeled[tweets_column].tolist())\n",
        "        augmented_samples.extend(back_translated_texts)\n",
        "\n",
        "    # Create a DataFrame for augmented data\n",
        "    augmented_labels = df_labeled['labels'].values.tolist() * augmentation_factor  # Same labels for augmented data\n",
        "    augmented_df = pd.DataFrame({tweets_column: augmented_samples, 'labels': augmented_labels})\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "# Assuming df_labeled is your original DataFrame with a column named 'labels'\n",
        "# Calculate the number of samples to augment for each label (20% of total)\n",
        "total_samples = len(df_labeled)\n",
        "num_samples_to_augment = int(total_samples * 0.2)\n",
        "\n",
        "# Calculate samples for each label (equal number)\n",
        "num_samples_per_label = num_samples_to_augment // 2\n",
        "\n",
        "# Separate the DataFrame into two subsets: one for each label\n",
        "df_label_0 = df_labeled[df_labeled['labels'] == 0]\n",
        "df_label_1 = df_labeled[df_labeled['labels'] == 1]\n",
        "\n",
        "# Randomly sample from each subset, ensuring equal representation\n",
        "df_label_0_sample = df_label_0.sample(n=num_samples_per_label, random_state=42)\n",
        "df_label_1_sample = df_label_1.sample(n=num_samples_per_label, random_state=42)\n",
        "\n",
        "# Combine the sampled data\n",
        "df_labeled_subset = pd.concat([df_label_0_sample, df_label_1_sample])\n",
        "\n",
        "# Print the selected subset (for verification)\n",
        "# print(\"Subset of Labeled Data for Augmentation:\")\n",
        "# print(df_labeled_subset)\n",
        "\n",
        "# Augment the selected subset\n",
        "augmented_data = augment_data_with_back_translation(df_labeled_subset, augmentation_factor=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlpAwew71NC0",
        "outputId": "163c6162-2343-4d3c-9c0c-9bad4be09a2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset of Labeled Data for Augmentation:\n",
            "                                                  tweets  labels\n",
            "9057                     thanks glad youre enjoying game       0\n",
            "17128  twitter today shaking hands meme people wary t...       0\n",
            "2899                               gotcha glad clarified       0\n",
            "5207                                     bdudley pleased       0\n",
            "15680                                   bdepression joke       0\n",
            "...                                                  ...     ...\n",
            "4998   bactually really vibing birthday year itxexxs ...       1\n",
            "2238                  shit gives anxiety looking anymore       1\n",
            "8913     want induce anxiety ancient space creacher hair       1\n",
            "6709                           seasonal depression photo       1\n",
            "2109   david ayers suicide squad optionalncyborg solo...       1\n",
            "\n",
            "[70 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Define random insertion, deletion, and swap functions\n",
        "bangla_stopwords= set(stopwords.words('english'))\n",
        "\n",
        "# Random insertion function for Bangla text\n",
        "def random_insertion(text, n=1):\n",
        "    words = text.split()  # Tokenize the Bangla sentence into words\n",
        "    for _ in range(n):\n",
        "        # Choose a random Bangla stopword and insert it into a random position\n",
        "        new_word = random.choice(list(bangla_stopwords))\n",
        "        pos = random.randint(0, len(words))\n",
        "        words.insert(pos, new_word)\n",
        "    return ' '.join(words)  # Join words back into a sentence\n",
        "\n",
        "def random_deletion(text, p=0.1):\n",
        "    words = text.split()\n",
        "    if len(words) == 1:\n",
        "        return text\n",
        "    # Randomly delete words with probability `p`\n",
        "    words = [word for word in words if random.random() > p]\n",
        "    return ' '.join(words) if words else text\n",
        "\n",
        "def random_swap(text, n=1):\n",
        "    words = text.split()\n",
        "    if len(words) < 2:\n",
        "        return text\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Function to apply augmentation to a subset of the unlabeled data\n",
        "def augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='insertion', fraction=0.1, n=1):\n",
        "    num_samples_to_augment = int(fraction * len(df_unlabeled))\n",
        "    df_sample = df_unlabeled.sample(n=num_samples_to_augment, random_state=42)\n",
        "\n",
        "    augmented_texts = []\n",
        "    for tweet in df_sample[tweets_column]:\n",
        "        if augment_type == 'insertion':\n",
        "            augmented_texts.append(random_insertion(tweet, n=n))\n",
        "        elif augment_type == 'deletion':\n",
        "            augmented_texts.append(random_deletion(tweet))\n",
        "        elif augment_type == 'swap':\n",
        "            augmented_texts.append(random_swap(tweet, n=n))\n",
        "\n",
        "    df_sample_augmented = df_sample.copy()\n",
        "    df_sample_augmented[tweets_column] = augmented_texts\n",
        "    return df_sample_augmented\n",
        "\n",
        "# Get the subsets of the unlabeled data for augmentation\n",
        "# 10% for each augmentation method\n",
        "df_unlabeled_insertion = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='insertion', fraction=0.06)\n",
        "df_unlabeled_deletion = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='deletion', fraction=0.05)\n",
        "df_unlabeled_swap = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='swap', fraction=0.06)\n",
        "\n",
        "# Combine the augmented samples\n",
        "df_unlabeled_augmented = pd.concat([df_unlabeled_insertion, df_unlabeled_deletion, df_unlabeled_swap])\n",
        "\n",
        "# Combine the augmented data with the remaining 70% of non-augmented unlabeled data\n",
        "df_unlabeled_combined = pd.concat([df_unlabeled_augmented, df_unlabeled], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "VH87pUSq1OQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e046bd-1c0a-4f8f-eb22-96923177b5ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_combined = pd.concat([df_labeled, augmented_data], ignore_index=True)\n",
        "\n",
        "# Re-tokenize the combined dataset for training\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df_combined[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "# Tokenize labeled data for training\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df_combined['labels'].values)\n",
        "\n",
        "# Tokenize unlabeled data\n",
        "encoded_data_unlabeled = tokenizer.batch_encode_plus(\n",
        "    df_unlabeled_combined[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_unlabeled = encoded_data_unlabeled['input_ids']\n",
        "attention_masks_unlabeled = encoded_data_unlabeled['attention_mask']\n",
        "#tokenize validation data\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df_val[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df_val['labels'].values)\n",
        "\n",
        "# Tokenize test data\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    df_test[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(df_test['labels'].values)\n",
        "\n",
        "# Create datasets\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_unlabeled = TensorDataset(input_ids_unlabeled, attention_masks_unlabeled)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "# Custom teacher model with dropout\n",
        "class CustomTeacherModel(torch.nn.Module):\n",
        "    def __init__(self, dropout_rate, num_labels):\n",
        "        super(CustomTeacherModel, self).__init__()\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=num_labels)\n",
        "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        logits = self.dropout(outputs.logits)\n",
        "        return outputs\n",
        "\n",
        "# Function to initialize teacher models with different seeds\n",
        "def initialize_teacher_model(seed, dropout_rate):\n",
        "    torch.manual_seed(seed)\n",
        "    return CustomTeacherModel(dropout_rate, NUM_LABELS)\n",
        "\n",
        "# Define seeds and dropout rates for each teacher model\n",
        "seeds = [42, 43, 44]\n",
        "dropout_rates = [0.1, 0.2, 0.3]\n",
        "\n",
        "# Initialize teacher models\n",
        "# Initialize student and teacher models\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=NUM_LABELS)\n",
        "teacher_model1 = initialize_teacher_model(seeds[0], dropout_rates[0])\n",
        "teacher_model2 = initialize_teacher_model(seeds[1], dropout_rates[1])\n",
        "teacher_model3 = initialize_teacher_model(seeds[2], dropout_rates[2])\n",
        "\n",
        "\n",
        "# Set up device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "student_model.to(device)\n",
        "teacher_model1.to(device)\n",
        "teacher_model2.to(device)\n",
        "teacher_model3.to(device)\n"
      ],
      "metadata": {
        "id": "JgfRYDL21TbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "898bd29f65df4fae99362ec6659108b8",
            "7214d56ad4b1422fa8998800ed32431e",
            "96174eadbab740d2ab36ad821b1ab315",
            "431e700be60a4d949393731a4c0c0e49",
            "218043e18c4c46679c031d273bf57d46",
            "5fa7c7a9318f40dda5b19a4f61f06c64",
            "9685045808314a34802de162021a22c5",
            "8a0c8aeb5665406d9ddc9a24a9c01bb5",
            "db2e7cd8a5854e16ac0b3988c757c251",
            "e374fddec2d04b75ba044d395538e48c",
            "78eabb9898bc4a3c8aeb2628dbc7a794"
          ]
        },
        "outputId": "2acc9b6b-c217-4f1c-dda9-1ab79e896caf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "898bd29f65df4fae99362ec6659108b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTeacherModel(\n",
              "  (model): XLMRobertaForSequenceClassification(\n",
              "    (roberta): XLMRobertaModel(\n",
              "      (embeddings): XLMRobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): XLMRobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-11): 12 x XLMRobertaLayer(\n",
              "            (attention): XLMRobertaAttention(\n",
              "              (self): XLMRobertaSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): XLMRobertaSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): XLMRobertaIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): XLMRobertaOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (classifier): XLMRobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer and scheduler for the student model\n",
        "optimizer = AdamW(student_model.parameters(), lr=1e-5, eps=1e-8)\n",
        "epochs = 6\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset_train) * epochs)\n",
        "\n",
        "# Split labeled data into three equal parts with stratification for each teacher model\n",
        "df_labeled_teacher1, df_temp_teacher = train_test_split(df_labeled, stratify=df_labeled[labels_column], test_size=2/3)\n",
        "df_labeled_teacher2, df_labeled_teacher3 = train_test_split(df_temp_teacher, stratify=df_temp_teacher[labels_column], test_size=1/2)\n",
        "\n",
        "# Function to tokenize data\n",
        "def tokenize_data(df):\n",
        "    encoded_data = tokenizer.batch_encode_plus(\n",
        "        df[tweets_column].tolist(),\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=256,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoded_data['input_ids']\n",
        "    attention_masks = encoded_data['attention_mask']\n",
        "    labels = torch.tensor(df[labels_column].values)\n",
        "    return TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Tokenize and create datasets for each teacher\n",
        "dataset_teacher1 = tokenize_data(df_labeled_teacher1)\n",
        "dataset_teacher2 = tokenize_data(df_labeled_teacher2)\n",
        "dataset_teacher3 = tokenize_data(df_labeled_teacher3)\n",
        "\n",
        "# Training loop with student and ensemble teachers\n",
        "def calculate_alpha1(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def calculate_alpha2(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def calculate_alpha3(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def update_teacher(teacher_model, student_model, alpha):\n",
        "    with torch.no_grad():\n",
        "        for teacher_param, student_param in zip(teacher_model.parameters(), student_model.parameters()):\n",
        "            teacher_param.data.mul_(alpha).add_(student_param.data, alpha=(1 - alpha))\n",
        "\n",
        "def compute_uncertainty(logits_teacher1, logits_teacher2, logits_teacher3):\n",
        "    variance = torch.var(torch.stack([logits_teacher1, logits_teacher2, logits_teacher3]), dim=0)\n",
        "    uncertainty = torch.mean(variance, dim=-1)\n",
        "    return uncertainty\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    accuracy = accuracy_score(labels_flat, preds_flat)\n",
        "    f1 = f1_score(labels_flat, preds_flat, average='weighted')\n",
        "    precision = precision_score(labels_flat, preds_flat, average='weighted')\n",
        "    recall = recall_score(labels_flat, preds_flat, average='weighted')\n",
        "    return accuracy, f1, precision, recall\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n"
      ],
      "metadata": {
        "id": "FcIU8Jvm1X5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7674645-71e1-40c0-87a5-e5cecb3d360d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from tqdm import tqdm\n",
        "# Training loop with IPL and pseudo-labeled data integration\n",
        "for epoch in range(1, epochs + 1):\n",
        "    student_model.train()\n",
        "    loss_train_total = 0\n",
        "\n",
        "    # Create DataLoaders for the current epoch\n",
        "    train_loader = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=8)\n",
        "    unlabeled_loader = DataLoader(dataset_unlabeled, sampler=RandomSampler(dataset_unlabeled), batch_size=8)\n",
        "\n",
        "    # Create iterators for training and unlabeled batches\n",
        "    train_iterator = iter(train_loader)\n",
        "    unlabeled_iterator = iter(unlabeled_loader)\n",
        "\n",
        "    # Calculate number of batches\n",
        "    num_train_batches = len(train_loader)\n",
        "    num_unlabeled_batches = len(unlabeled_loader)\n",
        "    max_batches = max(num_train_batches, num_unlabeled_batches)\n",
        "\n",
        "    # Progress bar for the maximum number of batches\n",
        "    progress_bar = tqdm(range(max_batches), desc=f'Epoch {epoch}', leave=False)\n",
        "\n",
        "    for _ in progress_bar:\n",
        "        try:\n",
        "            # Get the next training batch\n",
        "            train_batch = next(train_iterator)\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)  # Reset the iterator\n",
        "            train_batch = next(train_iterator)\n",
        "\n",
        "        train_batch = tuple(b.to(device) for b in train_batch)\n",
        "        inputs = {'input_ids': train_batch[0], 'attention_mask': train_batch[1], 'labels': train_batch[2]}\n",
        "\n",
        "        # Train the student on the labeled data (supervised loss)\n",
        "        outputs_student = student_model(**inputs)\n",
        "        loss_supervised = outputs_student.loss\n",
        "\n",
        "        # Get the corresponding unlabeled batch\n",
        "        try:\n",
        "            unlabeled_batch = next(unlabeled_iterator)\n",
        "        except StopIteration:\n",
        "            unlabeled_iterator = iter(unlabeled_loader)  # Reset the iterator\n",
        "            unlabeled_batch = next(unlabeled_iterator)\n",
        "\n",
        "        unlabeled_batch = tuple(b.to(device) for b in unlabeled_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits_teacher1 = teacher_model1(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            logits_teacher2 = teacher_model2(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            logits_teacher3 = teacher_model3(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            ensemble_logits = (logits_teacher1 + logits_teacher2 + logits_teacher3) / 3\n",
        "\n",
        "            # Compute uncertainty\n",
        "            uncertainty = compute_uncertainty(logits_teacher1, logits_teacher2, logits_teacher3)\n",
        "            uncertainty_weight = 1 / (1 + uncertainty)\n",
        "\n",
        "        # Student model predictions on unlabeled data\n",
        "        outputs_student_unlabeled = student_model(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1])\n",
        "        loss_consistency = F.mse_loss(outputs_student_unlabeled.logits, ensemble_logits) * uncertainty_weight.mean()\n",
        "\n",
        "        # Total loss\n",
        "        loss = loss_supervised + loss_consistency\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Cyclic teacher update based on the epoch number\n",
        "        if epoch % 3 == 1:\n",
        "            alpha1 = calculate_alpha1(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha2 = calculate_alpha2(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model1, student_model, alpha1)\n",
        "            update_teacher(teacher_model2, student_model, alpha2)\n",
        "        elif epoch % 3 == 2:\n",
        "            alpha2 = calculate_alpha2(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha3 = calculate_alpha3(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model2, student_model, alpha2)\n",
        "            update_teacher(teacher_model3, student_model, alpha3)\n",
        "        elif epoch % 3 == 0:\n",
        "            alpha1 = calculate_alpha1(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha3 = calculate_alpha3(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model3, student_model, alpha3)\n",
        "            update_teacher(teacher_model1, student_model, alpha1)\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f'\\nEpoch {epoch}: Loss: {loss_train_total / (max_batches * 8):.3f}')  # Total loss normalized by total batches\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Validation loop\n",
        "    student_model.eval()\n",
        "    teacher_model1.eval()\n",
        "    teacher_model2.eval()\n",
        "    teacher_model3.eval()\n",
        "    loss_val_total = 0\n",
        "    predictions_student, predictions_teacher1, predictions_teacher2, predictions_teacher3, true_vals = [], [], [], [], []\n",
        "\n",
        "    progress_bar_val = tqdm(DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=8),\n",
        "                            desc=f'Validation Epoch {epoch}', leave=False)\n",
        "\n",
        "    for batch in progress_bar_val:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            # Student model predictions\n",
        "            outputs_student = student_model(input_ids=batch[0], attention_mask=batch[1])\n",
        "            logits_student = outputs_student.logits\n",
        "            loss_val = F.cross_entropy(logits_student, batch[2])\n",
        "            loss_val_total += loss_val.item()\n",
        "\n",
        "            # Teacher model predictions\n",
        "            logits_teacher1 = teacher_model1(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits_teacher2 = teacher_model2(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits_teacher3 = teacher_model3(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "\n",
        "            # Collect predictions and true labels\n",
        "            predictions_student.append(logits_student.detach().cpu().numpy())\n",
        "            predictions_teacher1.append(logits_teacher1.detach().cpu().numpy())\n",
        "            predictions_teacher2.append(logits_teacher2.detach().cpu().numpy())\n",
        "            predictions_teacher3.append(logits_teacher3.detach().cpu().numpy())\n",
        "            true_vals.append(batch[2].cpu().numpy())\n",
        "\n",
        "        progress_bar_val.set_postfix({'validation_loss': f'{loss_val.item():.3f}'})\n",
        "\n",
        "    # Concatenate predictions and true labels\n",
        "    predictions_student = np.concatenate(predictions_student, axis=0)\n",
        "    predictions_teacher1 = np.concatenate(predictions_teacher1, axis=0)\n",
        "    predictions_teacher2 = np.concatenate(predictions_teacher2, axis=0)\n",
        "    predictions_teacher3 = np.concatenate(predictions_teacher3, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    # Compute metrics for student and teacher models\n",
        "    metrics_student = compute_metrics(predictions_student, true_vals)\n",
        "    metrics_teacher1 = compute_metrics(predictions_teacher1, true_vals)\n",
        "    metrics_teacher2 = compute_metrics(predictions_teacher2, true_vals)\n",
        "    metrics_teacher3 = compute_metrics(predictions_teacher3, true_vals)\n",
        "\n",
        "    # Print validation metrics\n",
        "    print(f'Epoch {epoch}: Validation Loss: {loss_val_total / len(dataset_test):.3f}')\n",
        "    print(f'Student Model - Accuracy: {metrics_student[0]:.3f}, F1 Score: {metrics_student[1]:.3f}, Precision: {metrics_student[2]:.3f}, Recall: {metrics_student[3]:.3f}')\n",
        "    print(f'Teacher Model 1 - Accuracy: {metrics_teacher1[0]:.3f}, F1 Score: {metrics_teacher1[1]:.3f}, Precision: {metrics_teacher1[2]:.3f}, Recall: {metrics_teacher1[3]:.3f}')\n",
        "    print(f'Teacher Model 2 - Accuracy: {metrics_teacher2[0]:.3f}, F1 Score: {metrics_teacher2[1]:.3f}, Precision: {metrics_teacher2[2]:.3f}, Recall: {metrics_teacher2[3]:.3f}')\n",
        "    print(f'Teacher Model 3 - Accuracy: {metrics_teacher3[0]:.3f}, F1 Score: {metrics_teacher3[1]:.3f}, Precision: {metrics_teacher3[2]:.3f}, Recall: {metrics_teacher3[3]:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Yh-bryH7oZ",
        "outputId": "59510838-6c90-46b7-a22e-c4ded322fdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: Loss: 0.055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation Loss: 0.044\n",
            "Student Model - Accuracy: 0.874, F1 Score: 0.873, Precision: 0.884, Recall: 0.874\n",
            "Teacher Model 1 - Accuracy: 0.867, F1 Score: 0.865, Precision: 0.883, Recall: 0.867\n",
            "Teacher Model 2 - Accuracy: 0.867, F1 Score: 0.865, Precision: 0.883, Recall: 0.867\n",
            "Teacher Model 3 - Accuracy: 0.499, F1 Score: 0.332, Precision: 0.249, Recall: 0.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: Loss: 0.033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Validation Loss: 0.046\n",
            "Student Model - Accuracy: 0.858, F1 Score: 0.856, Precision: 0.880, Recall: 0.858\n",
            "Teacher Model 1 - Accuracy: 0.867, F1 Score: 0.865, Precision: 0.883, Recall: 0.867\n",
            "Teacher Model 2 - Accuracy: 0.871, F1 Score: 0.869, Precision: 0.887, Recall: 0.871\n",
            "Teacher Model 3 - Accuracy: 0.871, F1 Score: 0.869, Precision: 0.887, Recall: 0.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  83%|████████▎ | 1272/1541 [25:55<05:29,  1.23s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "student_model.eval()\n",
        "teacher_model1.eval()\n",
        "teacher_model2.eval()\n",
        "teacher_model3.eval()\n",
        "loss_test_total = 0\n",
        "predictions_student, predictions_ensemble, true_vals = [], [], []\n",
        "\n",
        "# Use tqdm for the testing loop\n",
        "progress_bar_test = tqdm(DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=8),\n",
        "                         desc='Testing',\n",
        "                         leave=False,\n",
        "                         disable=False)\n",
        "\n",
        "for batch in progress_bar_test:\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    with torch.no_grad():\n",
        "        # Student model predictions\n",
        "        outputs_student = student_model(input_ids=batch[0], attention_mask=batch[1])\n",
        "        logits_student = outputs_student.logits\n",
        "        loss_test = F.cross_entropy(logits_student, batch[2])\n",
        "        loss_test_total += loss_test.item()\n",
        "\n",
        "        # Teacher model predictions\n",
        "        logits_teacher1 = teacher_model1(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "        logits_teacher2 = teacher_model2(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "        logits_teacher3 = teacher_model3(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "\n",
        "        # Ensemble predictions (average of teacher logits)\n",
        "        logits_ensemble = (logits_teacher1 + logits_teacher2 + logits_teacher3) / 3\n",
        "\n",
        "        # Collect predictions and true labels\n",
        "        predictions_student.append(logits_student.detach().cpu().numpy())\n",
        "        predictions_ensemble.append(logits_ensemble.detach().cpu().numpy())\n",
        "        true_vals.append(batch[2].cpu().numpy())\n",
        "\n",
        "    # Update the progress bar with the current test loss\n",
        "    progress_bar_test.set_postfix({'test_loss': f'{loss_test.item():.3f}'})\n",
        "\n",
        "# Concatenate predictions and true labels\n",
        "predictions_student = np.concatenate(predictions_student, axis=0)\n",
        "predictions_ensemble = np.concatenate(predictions_ensemble, axis=0)\n",
        "true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "# Compute metrics for student model\n",
        "accuracy_student, f1_student, precision_student, recall_student = compute_metrics(predictions_student, true_vals)\n",
        "\n",
        "# Compute metrics for ensemble of teacher models\n",
        "accuracy_ensemble, f1_ensemble, precision_ensemble, recall_ensemble = compute_metrics(predictions_ensemble, true_vals)\n",
        "\n",
        "# Print testing metrics for student and ensembled teacher models\n",
        "print(f'Test Loss: {loss_test_total / len(dataset_test):.3f}')\n",
        "print(f'Student Model - Accuracy: {accuracy_student:.3f}, F1 Score: {f1_student:.3f}, Precision: {precision_student:.3f}, Recall: {recall_student:.3f}')\n",
        "print(f'Ensembled Teacher Models - Accuracy: {accuracy_ensemble:.3f}, F1 Score: {f1_ensemble:.3f}, Precision: {precision_ensemble:.3f}, Recall: {recall_ensemble:.3f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "2xmF8Ug715vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8611bc24-80e4-495c-c0d7-cd76b5eb72a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.023\n",
            "Student Model - 0.874, F1 Score: 0.873, Precision: 0.884, Recall: 0.874\n",
            "Ensembled Teacher Models - Accuracy: 0.867, F1 Score: 0.865, Precision: 0.883, Recall: 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- LIME explainability with average of both student models ----\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer  # LIME Import\n",
        "# LIME for explainability: explain the output using the average of both student models\n",
        "class_names = list(label_dict.keys())\n",
        "explainer = LimeTextExplainer(class_names=class_names, split_expression='\\s+')\n",
        "\n",
        "def predict_average_students(texts):\n",
        "    encodings = tokenizer.batch_encode_plus(texts, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through both student models\n",
        "        outputs_student1 = teacher_model1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs_student2 = teacher_model2(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs_student3 = teacher_model3(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Average the logits of both student models\n",
        "        avg_logits = (outputs_student1.logits + outputs_student2.logits+outputs_student3.logits ) / 3.0\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        probs = F.softmax(avg_logits, dim=1).detach().cpu().numpy()\n",
        "\n",
        "    return probs\n",
        "\n",
        "# Explain a random sample from the test set\n",
        "random_idx = random.randint(0, len(df_test) - 1)\n",
        "text_sample = df_test.iloc[random_idx][tweets_column]\n",
        "true_label = df_test.iloc[random_idx][labels_column]\n",
        "print(f\"Sample text: {text_sample}\")\n",
        "print(f\"True label: {class_names[true_label]}\")\n",
        "\n",
        "# Use the new prediction function for LIME\n",
        "exp = explainer.explain_instance(text_sample, predict_average_students, num_features=10,num_samples=100)\n",
        "exp.show_in_notebook()"
      ],
      "metadata": {
        "id": "fG2CSs6u2N_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFsA78zL2X9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}