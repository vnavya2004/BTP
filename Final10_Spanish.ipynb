{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4NVi1vFSCb+GfG/aY0Axp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b96d7ba7e1fb43ae8de2c7999f8646a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c7f6a1edd54d2a9a59ce5aef11e4d4",
              "IPY_MODEL_85c669e9c58e43fb877008f1dc8acc29",
              "IPY_MODEL_0c3e0b804be14957a258c6ac64ccf791"
            ],
            "layout": "IPY_MODEL_181c0e2881724084a6799ac534d7aafe"
          }
        },
        "37c7f6a1edd54d2a9a59ce5aef11e4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6001f38b3df4a8e97fd0ec3f0aae537",
            "placeholder": "​",
            "style": "IPY_MODEL_c60f870bd0ea453b9aae0eddf0af3890",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "85c669e9c58e43fb877008f1dc8acc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8bcf1026dd441eb7c25bd1064cb238",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5e221483700487e864a5cba6b33eac1",
            "value": 25
          }
        },
        "0c3e0b804be14957a258c6ac64ccf791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430fea7ac6804076a613c8c7e3576063",
            "placeholder": "​",
            "style": "IPY_MODEL_1d8b798114104360b36cc2ae345a9d3c",
            "value": " 25.0/25.0 [00:00&lt;00:00, 424B/s]"
          }
        },
        "181c0e2881724084a6799ac534d7aafe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6001f38b3df4a8e97fd0ec3f0aae537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60f870bd0ea453b9aae0eddf0af3890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb8bcf1026dd441eb7c25bd1064cb238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5e221483700487e864a5cba6b33eac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "430fea7ac6804076a613c8c7e3576063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8b798114104360b36cc2ae345a9d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21586ca6773048f1a6649eec8da4524a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4238b768ed22428b92563e0c24fd5e81",
              "IPY_MODEL_9c8b702c58b7439982f5b36b9821c7b2",
              "IPY_MODEL_a11ab596a6f3422f88ab010decfb90c8"
            ],
            "layout": "IPY_MODEL_7b7dad73337f408cbedcd2e26924bcf8"
          }
        },
        "4238b768ed22428b92563e0c24fd5e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76c5a658c9544db98105e9417dc38569",
            "placeholder": "​",
            "style": "IPY_MODEL_99f1091c99474ca8ae1625a06b757f02",
            "value": "config.json: 100%"
          }
        },
        "9c8b702c58b7439982f5b36b9821c7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8836003862ed435baa811f16e5f3b705",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de516b9c93624411a6b2dcca7702cab1",
            "value": 615
          }
        },
        "a11ab596a6f3422f88ab010decfb90c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf4a661ab4846ecae99164c5ad6ab6b",
            "placeholder": "​",
            "style": "IPY_MODEL_b9cd98b05f7d4a33974eac7528297e73",
            "value": " 615/615 [00:00&lt;00:00, 25.7kB/s]"
          }
        },
        "7b7dad73337f408cbedcd2e26924bcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c5a658c9544db98105e9417dc38569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f1091c99474ca8ae1625a06b757f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8836003862ed435baa811f16e5f3b705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de516b9c93624411a6b2dcca7702cab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bf4a661ab4846ecae99164c5ad6ab6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cd98b05f7d4a33974eac7528297e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df524eabd7e46a899406bb43db2d482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471c1d8d19374dabb8027356ee83d009",
              "IPY_MODEL_e6724560d9de461dac7d41fc0293261f",
              "IPY_MODEL_918251d10d4b4f3092388199246153f6"
            ],
            "layout": "IPY_MODEL_7ea9d2d0c09c48fb98ef26f9d208062a"
          }
        },
        "471c1d8d19374dabb8027356ee83d009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0842b3fbc9b43f0ad617111e21d015a",
            "placeholder": "​",
            "style": "IPY_MODEL_0e51f416c34147418a6ae5b5ce6b6e52",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "e6724560d9de461dac7d41fc0293261f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e4b81e2c6f4e558547745158ad3003",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45bbfbed97714025bfec5abf18ad1ed4",
            "value": 5069051
          }
        },
        "918251d10d4b4f3092388199246153f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0283f800e304df8985fb380d561fecb",
            "placeholder": "​",
            "style": "IPY_MODEL_2f288b72269641fc9428f2c76c9f7d3f",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 24.4MB/s]"
          }
        },
        "7ea9d2d0c09c48fb98ef26f9d208062a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0842b3fbc9b43f0ad617111e21d015a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e51f416c34147418a6ae5b5ce6b6e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e4b81e2c6f4e558547745158ad3003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bbfbed97714025bfec5abf18ad1ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0283f800e304df8985fb380d561fecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f288b72269641fc9428f2c76c9f7d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f87e4b9012094a698f5bd127fc9689c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5df2c29608d4bb3b11230a644670fc8",
              "IPY_MODEL_a2d931f90e36400b821ae32bf39f0bc0",
              "IPY_MODEL_87a499d4cb3146f491416f7b0cd6ace6"
            ],
            "layout": "IPY_MODEL_0b26a3d5e7a9489ab52e72e88c27438c"
          }
        },
        "b5df2c29608d4bb3b11230a644670fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef19c79859d4f32985dd2a893b3a3b4",
            "placeholder": "​",
            "style": "IPY_MODEL_81c15b09b6bf4ffc963a9fc867d41a16",
            "value": "tokenizer.json: 100%"
          }
        },
        "a2d931f90e36400b821ae32bf39f0bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee99472ca89406a9f705d403ce094c4",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_565bf8740efb42e6be3714c959877979",
            "value": 9096718
          }
        },
        "87a499d4cb3146f491416f7b0cd6ace6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db7d3516fc534707bcecde6d7aaddaa8",
            "placeholder": "​",
            "style": "IPY_MODEL_46ec275085ac494db409ca0189800672",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 49.1MB/s]"
          }
        },
        "0b26a3d5e7a9489ab52e72e88c27438c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef19c79859d4f32985dd2a893b3a3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c15b09b6bf4ffc963a9fc867d41a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee99472ca89406a9f705d403ce094c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565bf8740efb42e6be3714c959877979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db7d3516fc534707bcecde6d7aaddaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ec275085ac494db409ca0189800672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnavya2004/BTP/blob/main/Final10_Spanish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9FsLZuxIXbQ",
        "outputId": "3b97554b-84c8-4a39-983d-faef50e02fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=80b24fda3645d09b840b98d36a715cc2dcfaf656578c14fca280b57c88e2660c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "# Load the XLM-RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Assuming you're using Google Colab and uploaded a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel(pd.ExcelFile(list(uploaded.keys())[0]), header=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "b96d7ba7e1fb43ae8de2c7999f8646a7",
            "37c7f6a1edd54d2a9a59ce5aef11e4d4",
            "85c669e9c58e43fb877008f1dc8acc29",
            "0c3e0b804be14957a258c6ac64ccf791",
            "181c0e2881724084a6799ac534d7aafe",
            "d6001f38b3df4a8e97fd0ec3f0aae537",
            "c60f870bd0ea453b9aae0eddf0af3890",
            "eb8bcf1026dd441eb7c25bd1064cb238",
            "d5e221483700487e864a5cba6b33eac1",
            "430fea7ac6804076a613c8c7e3576063",
            "1d8b798114104360b36cc2ae345a9d3c",
            "21586ca6773048f1a6649eec8da4524a",
            "4238b768ed22428b92563e0c24fd5e81",
            "9c8b702c58b7439982f5b36b9821c7b2",
            "a11ab596a6f3422f88ab010decfb90c8",
            "7b7dad73337f408cbedcd2e26924bcf8",
            "76c5a658c9544db98105e9417dc38569",
            "99f1091c99474ca8ae1625a06b757f02",
            "8836003862ed435baa811f16e5f3b705",
            "de516b9c93624411a6b2dcca7702cab1",
            "6bf4a661ab4846ecae99164c5ad6ab6b",
            "b9cd98b05f7d4a33974eac7528297e73",
            "4df524eabd7e46a899406bb43db2d482",
            "471c1d8d19374dabb8027356ee83d009",
            "e6724560d9de461dac7d41fc0293261f",
            "918251d10d4b4f3092388199246153f6",
            "7ea9d2d0c09c48fb98ef26f9d208062a",
            "d0842b3fbc9b43f0ad617111e21d015a",
            "0e51f416c34147418a6ae5b5ce6b6e52",
            "70e4b81e2c6f4e558547745158ad3003",
            "45bbfbed97714025bfec5abf18ad1ed4",
            "e0283f800e304df8985fb380d561fecb",
            "2f288b72269641fc9428f2c76c9f7d3f",
            "f87e4b9012094a698f5bd127fc9689c8",
            "b5df2c29608d4bb3b11230a644670fc8",
            "a2d931f90e36400b821ae32bf39f0bc0",
            "87a499d4cb3146f491416f7b0cd6ace6",
            "0b26a3d5e7a9489ab52e72e88c27438c",
            "fef19c79859d4f32985dd2a893b3a3b4",
            "81c15b09b6bf4ffc963a9fc867d41a16",
            "6ee99472ca89406a9f705d403ce094c4",
            "565bf8740efb42e6be3714c959877979",
            "db7d3516fc534707bcecde6d7aaddaa8",
            "46ec275085ac494db409ca0189800672"
          ]
        },
        "id": "35ilKGviIgkJ",
        "outputId": "d3bce3c6-1d0c-4d0a-a94e-adb46f272efc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b96d7ba7e1fb43ae8de2c7999f8646a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21586ca6773048f1a6649eec8da4524a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4df524eabd7e46a899406bb43db2d482"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f87e4b9012094a698f5bd127fc9689c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b53d6eaa-ff4e-4fe2-96bc-72721f3c5ba0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b53d6eaa-ff4e-4fe2-96bc-72721f3c5ba0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spanish.xlsx to spanish.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zZAIXQbSI3-e",
        "outputId": "74f60091-658d-48ff-c8af-0952a1a28399"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                             Tweets  Labels\n",
              "0         NaN  DeberÃ­an eliminar a las malas personas y a lo...       1\n",
              "1         NaN  Ya deja de intentar contarle tus problemas a a...       1\n",
              "2         NaN  La tristeza es lo mÃ¡s fÃ¡cil de ocultar de to...       1\n",
              "3         NaN  De las peores cosas de la depresiÃ³n es que no...       1\n",
              "4         NaN  La soledad es lo Ãºnico constante en mi vida. ...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-904a158b-7b21-4ba9-9368-29644752e8fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>DeberÃ­an eliminar a las malas personas y a lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Ya deja de intentar contarle tus problemas a a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>La tristeza es lo mÃ¡s fÃ¡cil de ocultar de to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>De las peores cosas de la depresiÃ³n es que no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>La soledad es lo Ãºnico constante en mi vida. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-904a158b-7b21-4ba9-9368-29644752e8fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-904a158b-7b21-4ba9-9368-29644752e8fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-904a158b-7b21-4ba9-9368-29644752e8fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f2bfc4b-fb61-45b2-8c2b-cfebd9c59ace\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f2bfc4b-fb61-45b2-8c2b-cfebd9c59ace')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f2bfc4b-fb61-45b2-8c2b-cfebd9c59ace button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2186,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2179,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the dataset into two based on label 0 and label 1\n",
        "df_0 = df[df['Labels'] == 0]\n",
        "df_1 = df[df['Labels'] == 1]\n",
        "\n",
        "# Find the minimum count between both labels\n",
        "min_count = min(len(df_0), len(df_1))\n",
        "\n",
        "print(min_count)\n",
        "# Reduce both datasets to the minimum count\n",
        "df_0_reduced = df_0.sample(n=min_count, random_state=42)\n",
        "df_1_reduced = df_1.sample(n=min_count, random_state=42)\n",
        "\n",
        "# Concatenate both reduced datasets\n",
        "df_balanced = pd.concat([df_0_reduced, df_1_reduced])\n",
        "\n",
        "# Shuffle the dataset\n",
        "df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(df[df['Labels'] == 0])\n",
        "print(df[df['Labels'] == 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQDd2wIFIrVP",
        "outputId": "b5dbaaea-eb8d-41e1-f19b-6c1be67301ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "      Unnamed: 0                                             Tweets  Labels\n",
            "1            NaN  grita al vacío conmigo aaaaaaaaaaaaaaaaaaaaaaa...       0\n",
            "3            NaN  Feliz espero que tengas felices vidas diurnas ...       0\n",
            "6            NaN  ¿Cuántas lecciones de conducción tenías antes ...       0\n",
            "8            NaN           quiero ser racista el racista más rápido       0\n",
            "10           NaN  Quiero saber la proporción de personas cachond...       0\n",
            "...          ...                                                ...     ...\n",
            "1985         NaN  El nervio, el agallón, la audacia de las perso...       0\n",
            "1987         NaN  Sinceramente, es mucho más agradable saber que...       0\n",
            "1989         NaN  Mi maestra realmente me brindó que cambió mi c...       0\n",
            "1990         NaN  Si los días escolares son los mejores días de ...       0\n",
            "1997         NaN  ¿Cómo puedo superar a la chica que me gusta? A...       0\n",
            "\n",
            "[1000 rows x 3 columns]\n",
            "      Unnamed: 0                                             Tweets  Labels\n",
            "0            NaN  Que pare de doler. Por favor, por favor, por f...       1\n",
            "2            NaN  Supongo que algo si es cierto. La mayorÃ­a del...       1\n",
            "4            NaN  Estoy cansada de todo y de todos ojala esto fu...       1\n",
            "5            NaN  Quiero estar bien y no lo consigo, por mucho q...       1\n",
            "7            NaN  No puedo entender cÃ³mo, pero mi vida cada dÃ­...       1\n",
            "...          ...                                                ...     ...\n",
            "1994         NaN       Me levante queriendo que el dÃ­a acabara ya.       1\n",
            "1995         NaN  hoy mientras tenÃ­a un ataque de ansiedad mi m...       1\n",
            "1996         NaN              Soy un fracaso en todos los sentidos.       1\n",
            "1998         NaN                              Me siento tan solo...       1\n",
            "1999         NaN  Como pretendo que alguien me quiera, si yo no ...       1\n",
            "\n",
            "[1000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_column = 'Tweets'\n",
        "labels_column = 'Labels'\n",
        "NUM_LABELS = len(df[labels_column].unique())\n",
        "possible_labels = df[labels_column].unique()\n",
        "label_dict = {possible_label: index for index, possible_label in enumerate(possible_labels)}\n",
        "df['Labels'] = df[labels_column].map(label_dict)\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Initialize tokenizer and stemmer for Bangla\n",
        "\n",
        "\n",
        "# Download stopwords (assuming Bangla stopwords are available)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load Bangla stopwords (you can customize this set with your own stopwords if needed)\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "print(stop_words)\n",
        "# Preprocessing function for Bangla text\n",
        "def preprocess_bangla_tweet(tweet):\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove special characters and digits\n",
        "    tweet = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ\\s]', '', tweet)\n",
        "\n",
        "\n",
        "    # Tokenize the tweet\n",
        "    words = tweet.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stem words (you can use stemming or lemmatization as per availability)\n",
        "    words = [word for word in words]\n",
        "\n",
        "    # Join the cleaned words back into a string\n",
        "    tweet = ' '.join(words)\n",
        "\n",
        "    return tweet\n",
        "\n",
        "# Apply preprocessing to the 'tweets' column\n",
        "df[tweets_column] = df[tweets_column].apply(preprocess_bangla_tweet)\n",
        "\n",
        "\n",
        "# Split dataset into labeled (20%), unlabeled (60%), and test (20%) sets\n",
        "df_labeled, df_temp = train_test_split(df, stratify=df[labels_column], test_size=0.8)\n",
        "df_unlabeled, df_temp_val_test = train_test_split(df_temp, stratify=df_temp[labels_column], test_size=0.25)\n",
        "df_val, df_test = train_test_split(df_temp_val_test, stratify=df_temp_val_test[labels_column], test_size=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0AFIV_zI1qK",
        "outputId": "18206941-21d6-4319-9b8a-73fbe3775a78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tuyas', 'nuestro', 'qué', 'tengas', 'tendréis', 'sus', 'serían', 'quienes', 'nuestras', 'eran', 'hasta', 'su', 'tuviese', 'estuviste', 'son', 'fueran', 'el', 'como', 'estabais', 'teniendo', 'este', 'nosotros', 'también', 'cuando', 'donde', 'sois', 'quien', 'estuviesen', 'habríamos', 'habrás', 'fueron', 'pero', 'tuve', 'soy', 'e', 'tuviesen', 'hubieran', 'he', 'tuviste', 'hubiesen', 'fueseis', 'le', 'mucho', 'muchos', 'del', 'habría', 'tenía', 'tuvieseis', 'antes', 'estando', 'por', 'hubieras', 'eso', 'estaríamos', 'estuvieron', 'fuesen', 'no', 'esto', 'los', 'tiene', 'suya', 'habré', 'serías', 'poco', 'o', 'erais', 'hay', 'ese', 'sintiendo', 'hayamos', 'la', 'nuestra', 'estás', 'fuisteis', 'ellas', 'tuyos', 'tenemos', 'desde', 'teníais', 'tienen', 'fueras', 'tendrá', 'un', 'fuésemos', 'una', 'te', 'estaban', 'estuviese', 'sentidos', 'con', 'tuvieras', 'nosotras', 'ellos', 'mi', 'fuerais', 'tendré', 'estuvieran', 'hube', 'fuimos', 'estemos', 'estuvieras', 'tu', 'habido', 'sentidas', 'hubieron', 'estén', 'hayáis', 'estamos', 'seríamos', 'hemos', 'seas', 'vosotras', 'fueses', 'hubiésemos', 'vuestros', 'hubierais', 'estuvisteis', 'ti', 'vuestro', 'habríais', 'esa', 'hubieses', 'para', 'suyas', 'lo', 'hubieseis', 'habías', 'estábamos', 'será', 'todo', 'ya', 'y', 'tenidos', 'estuviéramos', 'esos', 'están', 'estaríais', 'habidos', 'sería', 'sea', 'seáis', 'uno', 'nuestros', 'tengan', 'tengo', 'míos', 'suyo', 'otras', 'estarás', 'estéis', 'tendrían', 'tenga', 'cual', 'sobre', 'tuya', 'algunas', 'vuestras', 'estada', 'habidas', 'tuvo', 'habéis', 'estas', 'tendrán', 'fui', 'él', 'estados', 'ante', 'tuvieran', 'tú', 'habrían', 'ni', 'estará', 'estoy', 'más', 'ha', 'estáis', 'hubiste', 'tenían', 'seamos', 'hubiese', 'habrán', 'hubo', 'estaremos', 'estuvimos', 'tuvieron', 'tenido', 'fuiste', 'fue', 'las', 'estarían', 'habida', 'estuvieses', 'os', 'esté', 'está', 'de', 'han', 'éramos', 'era', 'somos', 'todos', 'estuvierais', 'habrías', 'algunos', 'estadas', 'serás', 'hubimos', 'seré', 'tendríais', 'es', 'estuviésemos', 'mí', 'esas', 'sean', 'tendrás', 'estaría', 'tenidas', 'habían', 'sin', 'siente', 'sentid', 'tenéis', 'tuvierais', 'habremos', 'tendrías', 'tendríamos', 'mis', 'seremos', 'al', 'en', 'tuviésemos', 'mías', 'haya', 'tienes', 'estés', 'fuéramos', 'estuvieseis', 'tenías', 'tendremos', 'porque', 'vosotros', 'me', 'otros', 'tus', 'tened', 'les', 'tuviera', 'otra', 'mía', 'tuyo', 'que', 'habrá', 'unos', 'estaré', 'estarías', 'tuvisteis', 'serán', 'sentido', 'estad', 'esta', 'tengamos', 'hubiera', 'se', 'estos', 'estado', 'estarán', 'nos', 'estuvo', 'tanto', 'ella', 'mío', 'hubisteis', 'estaba', 'habíais', 'suyos', 'yo', 'estar', 'sentida', 'tuvieses', 'sí', 'seréis', 'tengáis', 'estuve', 'fuese', 'has', 'estabas', 'durante', 'tenida', 'hayas', 'vuestra', 'fuera', 'contra', 'tendría', 'seríais', 'tuvimos', 'entre', 'había', 'tuviéramos', 'estuviera', 'nada', 'algo', 'hayan', 'eres', 'hubiéramos', 'estaréis', 'habiendo', 'habréis', 'a', 'teníamos', 'muy', 'otro', 'eras', 'habíamos'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load translation models\n",
        "src_to_tgt_model_name = 'Helsinki-NLP/opus-mt-es-en'\n",
        "tgt_to_src_model_name = 'Helsinki-NLP/opus-mt-en-es'\n",
        "\n",
        "\n",
        "src_to_tgt_model = MarianMTModel.from_pretrained(src_to_tgt_model_name)\n",
        "src_to_tgt_tokenizer = MarianTokenizer.from_pretrained(src_to_tgt_model_name)\n",
        "\n",
        "tgt_to_src_model = MarianMTModel.from_pretrained(tgt_to_src_model_name)\n",
        "tgt_to_src_tokenizer = MarianTokenizer.from_pretrained(tgt_to_src_model_name)\n",
        "\n",
        "def back_translate(texts):\n",
        "    # Translate Bangla to English\n",
        "    translated = src_to_tgt_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated_texts = src_to_tgt_model.generate(**translated)\n",
        "    translated_texts = [src_to_tgt_tokenizer.decode(t, skip_special_tokens=True) for t in translated_texts]\n",
        "\n",
        "    # Translate English back to Bangla\n",
        "    back_translated = tgt_to_src_tokenizer(translated_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    back_translated_texts = tgt_to_src_model.generate(**back_translated)\n",
        "    back_translated_texts = [tgt_to_src_tokenizer.decode(t, skip_special_tokens=True) for t in back_translated_texts]\n",
        "\n",
        "    return back_translated_texts\n",
        "# Generate back-translated samples for labeled data\n",
        "def augment_data_with_back_translation(df_labeled, augmentation_factor=1):\n",
        "    augmented_samples = []\n",
        "\n",
        "    for _ in range(augmentation_factor):\n",
        "        # Back-translate the tweets\n",
        "        back_translated_texts = back_translate(df_labeled[tweets_column].tolist())\n",
        "        augmented_samples.extend(back_translated_texts)\n",
        "\n",
        "    # Create a DataFrame for augmented data\n",
        "    augmented_labels = df_labeled['Labels'].values.tolist() * augmentation_factor  # Same labels for augmented data\n",
        "    augmented_df = pd.DataFrame({tweets_column: augmented_samples, 'Labels': augmented_labels})\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "# Assuming df_labeled is your original DataFrame with a column named 'labels'\n",
        "# Calculate the number of samples to augment for each label (20% of total)\n",
        "total_samples = len(df_labeled)\n",
        "num_samples_to_augment = int(total_samples * 0.2)\n",
        "\n",
        "# Calculate samples for each label (equal number)\n",
        "num_samples_per_label = num_samples_to_augment // 2\n",
        "\n",
        "# Separate the DataFrame into two subsets: one for each label\n",
        "df_label_0 = df_labeled[df_labeled['Labels'] == 0]\n",
        "df_label_1 = df_labeled[df_labeled['Labels'] == 1]\n",
        "\n",
        "# Randomly sample from each subset, ensuring equal representation\n",
        "df_label_0_sample = df_label_0.sample(n=num_samples_per_label, random_state=42)\n",
        "df_label_1_sample = df_label_1.sample(n=num_samples_per_label, random_state=42)\n",
        "\n",
        "# Combine the sampled data\n",
        "df_labeled_subset = pd.concat([df_label_0_sample, df_label_1_sample])\n",
        "\n",
        "# Print the selected subset (for verification)\n",
        "print(\"Subset of Labeled Data for Augmentation:\")\n",
        "print(df_labeled_subset)\n",
        "\n",
        "# Augment the selected subset\n",
        "augmented_data = augment_data_with_back_translation(df_labeled_subset, augmentation_factor=1)\n",
        "\n",
        "# Display the augmented data for further use\n",
        "print(\"Augmented Data:\")\n",
        "print(augmented_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "93U0KmxeJKPl",
        "outputId": "289d9e01-19dd-4a07-ce70-f372ddb62f25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset of Labeled Data for Augmentation:\n",
            "      Unnamed: 0                                             Tweets  Labels\n",
            "1546         NaN               Me pone nerviosa lugar queden viendo       0\n",
            "317          NaN                 No lleg Siempre qued parada camino       0\n",
            "1981         NaN  Estoy cansado mas all fsico tambin sentimental...       0\n",
            "1497         NaN     Perdn ser inestable insegurotmido fin desastre       0\n",
            "311          NaN                                 Todo hago hago mal       0\n",
            "...          ...                                                ...     ...\n",
            "181          NaN  Lindo suéter literalmente solo pensé suéter li...       1\n",
            "1547         NaN  Tuve primer beso hoy puedo decir demonios gran...       1\n",
            "1169         NaN  dando hechos aleatorios diarios aburridoLas nu...       1\n",
            "1737         NaN             Me voy matar meses voy mentir asustado       1\n",
            "833          NaN  Una vez barco puso relleno relleno relleno mar...       1\n",
            "\n",
            "[80 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d81a0a6f68ba>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Augment the selected subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0maugmented_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_data_with_back_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_labeled_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Display the augmented data for further use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d81a0a6f68ba>\u001b[0m in \u001b[0;36maugment_data_with_back_translation\u001b[0;34m(df_labeled, augmentation_factor)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Create a DataFrame for augmented data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0maugmented_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_labeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maugmentation_factor\u001b[0m  \u001b[0;31m# Same labels for augmented data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0maugmented_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtweets_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maugmented_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maugmented_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Define random insertion, deletion, and swap functions\n",
        "bangla_stopwords= set(stopwords.words('spanish'))\n",
        "\n",
        "# Random insertion function for Bangla text\n",
        "def random_insertion(text, n=1):\n",
        "    words = text.split()  # Tokenize the Bangla sentence into words\n",
        "    for _ in range(n):\n",
        "        # Choose a random Bangla stopword and insert it into a random position\n",
        "        new_word = random.choice(list(bangla_stopwords))\n",
        "        pos = random.randint(0, len(words))\n",
        "        words.insert(pos, new_word)\n",
        "    return ' '.join(words)  # Join words back into a sentence\n",
        "\n",
        "def random_deletion(text, p=0.1):\n",
        "    words = text.split()\n",
        "    if len(words) == 1:\n",
        "        return text\n",
        "    # Randomly delete words with probability `p`\n",
        "    words = [word for word in words if random.random() > p]\n",
        "    return ' '.join(words) if words else text\n",
        "\n",
        "def random_swap(text, n=1):\n",
        "    words = text.split()\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Function to apply augmentation to a subset of the unlabeled data\n",
        "def augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='insertion', fraction=0.1, n=1):\n",
        "    num_samples_to_augment = int(fraction * len(df_unlabeled))\n",
        "    df_sample = df_unlabeled.sample(n=num_samples_to_augment, random_state=42)\n",
        "\n",
        "    augmented_texts = []\n",
        "    for tweet in df_sample[tweets_column]:\n",
        "        if augment_type == 'insertion':\n",
        "            augmented_texts.append(random_insertion(tweet, n=n))\n",
        "        elif augment_type == 'deletion':\n",
        "            augmented_texts.append(random_deletion(tweet))\n",
        "        elif augment_type == 'swap':\n",
        "            augmented_texts.append(random_swap(tweet, n=n))\n",
        "\n",
        "    df_sample_augmented = df_sample.copy()\n",
        "    df_sample_augmented[tweets_column] = augmented_texts\n",
        "    return df_sample_augmented\n",
        "\n",
        "# Get the subsets of the unlabeled data for augmentation\n",
        "# 10% for each augmentation method\n",
        "df_unlabeled_insertion = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='insertion', fraction=0.06)\n",
        "df_unlabeled_deletion = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='deletion', fraction=0.05)\n",
        "df_unlabeled_swap = augment_unlabeled_data(df_unlabeled, tweets_column, augment_type='swap', fraction=0.06)\n",
        "\n",
        "# Combine the augmented samples\n",
        "df_unlabeled_augmented = pd.concat([df_unlabeled_insertion, df_unlabeled_deletion, df_unlabeled_swap])\n",
        "\n",
        "# Combine the augmented data with the remaining 70% of non-augmented unlabeled data\n",
        "df_unlabeled_combined = pd.concat([df_unlabeled_augmented, df_unlabeled], ignore_index=True)\n",
        "\n",
        "\n",
        "print(len(df_unlabeled_combined))"
      ],
      "metadata": {
        "id": "cIZV9ewPJecR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df_labeled, augmented_data], ignore_index=True)\n",
        "\n",
        "# Re-tokenize the combined dataset for training\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df_combined[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "# Tokenize labeled data for training\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df_combined['Labels'].values)\n",
        "\n",
        "# Tokenize unlabeled data\n",
        "encoded_data_unlabeled = tokenizer.batch_encode_plus(\n",
        "    df_unlabeled_combined[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_unlabeled = encoded_data_unlabeled['input_ids']\n",
        "attention_masks_unlabeled = encoded_data_unlabeled['attention_mask']\n",
        "#tokenize validation data\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df_val[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df_val['Labels'].values)\n",
        "\n",
        "# Tokenize test data\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    df_test[tweets_column].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(df_test['Labels'].values)\n",
        "\n",
        "# Create datasets\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_unlabeled = TensorDataset(input_ids_unlabeled, attention_masks_unlabeled)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "# Custom teacher model with dropout\n",
        "class CustomTeacherModel(torch.nn.Module):\n",
        "    def __init__(self, dropout_rate, num_labels):\n",
        "        super(CustomTeacherModel, self).__init__()\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=num_labels)\n",
        "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        logits = self.dropout(outputs.logits)\n",
        "        return outputs\n",
        "\n",
        "# Function to initialize teacher models with different seeds\n",
        "def initialize_teacher_model(seed, dropout_rate):\n",
        "    torch.manual_seed(seed)\n",
        "    return CustomTeacherModel(dropout_rate, NUM_LABELS)\n",
        "\n",
        "# Define seeds and dropout rates for each teacher model\n",
        "seeds = [42, 43, 44]\n",
        "dropout_rates = [0.1, 0.2, 0.3]\n",
        "\n",
        "# Initialize teacher models\n",
        "# Initialize student and teacher models\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=NUM_LABELS)\n",
        "teacher_model1 = initialize_teacher_model(seeds[0], dropout_rates[0])\n",
        "teacher_model2 = initialize_teacher_model(seeds[1], dropout_rates[1])\n",
        "teacher_model3 = initialize_teacher_model(seeds[2], dropout_rates[2])\n",
        "\n",
        "\n",
        "# Set up device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "student_model.to(device)\n",
        "teacher_model1.to(device)\n",
        "teacher_model2.to(device)\n",
        "teacher_model3.to(device)"
      ],
      "metadata": {
        "id": "HkeSYp0lJ2Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer and scheduler for the student model\n",
        "optimizer = AdamW(student_model.parameters(), lr=1e-5, eps=1e-8)\n",
        "epochs = 6\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataset_train) * epochs)\n",
        "\n",
        "# Split labeled data into three equal parts with stratification for each teacher model\n",
        "df_labeled_teacher1, df_temp_teacher = train_test_split(df_labeled, stratify=df_labeled[labels_column], test_size=2/3)\n",
        "df_labeled_teacher2, df_labeled_teacher3 = train_test_split(df_temp_teacher, stratify=df_temp_teacher[labels_column], test_size=1/2)\n",
        "\n",
        "# Function to tokenize data\n",
        "def tokenize_data(df):\n",
        "    encoded_data = tokenizer.batch_encode_plus(\n",
        "        df[tweets_column].tolist(),\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=256,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoded_data['input_ids']\n",
        "    attention_masks = encoded_data['attention_mask']\n",
        "    labels = torch.tensor(df[labels_column].values)\n",
        "    return TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Tokenize and create datasets for each teacher\n",
        "dataset_teacher1 = tokenize_data(df_labeled_teacher1)\n",
        "dataset_teacher2 = tokenize_data(df_labeled_teacher2)\n",
        "dataset_teacher3 = tokenize_data(df_labeled_teacher3)\n",
        "\n",
        "# Training loop with student and ensemble teachers\n",
        "def calculate_alpha1(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def calculate_alpha2(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def calculate_alpha3(epoch, total_epochs, base_alpha=0.95, final_alpha=0.999):\n",
        "    alpha = base_alpha + (final_alpha - base_alpha) * (epoch / total_epochs)\n",
        "    return alpha\n",
        "\n",
        "def update_teacher(teacher_model, student_model, alpha):\n",
        "    with torch.no_grad():\n",
        "        for teacher_param, student_param in zip(teacher_model.parameters(), student_model.parameters()):\n",
        "            teacher_param.data.mul_(alpha).add_(student_param.data, alpha=(1 - alpha))\n",
        "\n",
        "def compute_uncertainty(logits_teacher1, logits_teacher2, logits_teacher3):\n",
        "    variance = torch.var(torch.stack([logits_teacher1, logits_teacher2, logits_teacher3]), dim=0)\n",
        "    uncertainty = torch.mean(variance, dim=-1)\n",
        "    return uncertainty\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    accuracy = accuracy_score(labels_flat, preds_flat)\n",
        "    f1 = f1_score(labels_flat, preds_flat, average='weighted')\n",
        "    precision = precision_score(labels_flat, preds_flat, average='weighted')\n",
        "    recall = recall_score(labels_flat, preds_flat, average='weighted')\n",
        "    return accuracy, f1, precision, recall\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset"
      ],
      "metadata": {
        "id": "-iv02zXMKr5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to label pseudo-data using teacher models with confidence threshold\n",
        "def label_pseudo_data(teacher_model1, teacher_model2, teacher_model3, dataset_unlabeled, confidence_threshold=0.95):\n",
        "    pseudo_labels = []\n",
        "    pseudo_confidence = []\n",
        "    max_confidence = 0  # Initialize max confidence variable\n",
        "\n",
        "    data_loader_unlabeled = DataLoader(dataset_unlabeled, sampler=SequentialSampler(dataset_unlabeled), batch_size=8)\n",
        "    for batch in tqdm(data_loader_unlabeled, desc=\"Labeling Pseudo-Data\"):\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            logits1 = teacher_model1(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits2 = teacher_model2(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits3 = teacher_model3(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            ensemble_logits = (logits1 + logits2 + logits3) / 3\n",
        "            probabilities = torch.nn.functional.softmax(ensemble_logits, dim=-1)\n",
        "            confidences, predicted_labels = torch.max(probabilities, dim=-1)\n",
        "\n",
        "        # Track the maximum confidence\n",
        "        max_confidence = max(max_confidence, confidences.max().item())\n",
        "\n",
        "        print(f'max_confidence: {max_confidence}')\n",
        "\n",
        "        # Append all predicted labels and confidences to the lists\n",
        "        pseudo_labels.append(predicted_labels)\n",
        "        pseudo_confidence.append(confidences)\n",
        "\n",
        "    # Concatenate all pseudo labels and confidences\n",
        "    pseudo_labels = torch.cat(pseudo_labels, dim=0)\n",
        "    pseudo_confidence = torch.cat(pseudo_confidence, dim=0)\n",
        "\n",
        "    # After the loop in label_pseudo_data function\n",
        "    print(f'Total pseudo-labels generated: {len(pseudo_labels[pseudo_confidence >= 0.95])}')\n",
        "\n",
        "\n",
        "    return pseudo_labels, pseudo_confidence"
      ],
      "metadata": {
        "id": "zW2MgUobK6Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop with IPL and pseudo-labeled data integration\n",
        "for epoch in range(1, epochs + 1):\n",
        "    student_model.train()\n",
        "    loss_train_total = 0\n",
        "\n",
        "    # Create DataLoaders for the current epoch\n",
        "    train_loader = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=8)\n",
        "    unlabeled_loader = DataLoader(dataset_unlabeled, sampler=RandomSampler(dataset_unlabeled), batch_size=8)\n",
        "\n",
        "    # Create iterators for training and unlabeled batches\n",
        "    train_iterator = iter(train_loader)\n",
        "    unlabeled_iterator = iter(unlabeled_loader)\n",
        "\n",
        "    # Calculate number of batches\n",
        "    num_train_batches = len(train_loader)\n",
        "    num_unlabeled_batches = len(unlabeled_loader)\n",
        "    max_batches = max(num_train_batches, num_unlabeled_batches)\n",
        "\n",
        "    # Progress bar for the maximum number of batches\n",
        "    progress_bar = tqdm(range(max_batches), desc=f'Epoch {epoch}', leave=False)\n",
        "\n",
        "    for _ in progress_bar:\n",
        "        try:\n",
        "            # Get the next training batch\n",
        "            train_batch = next(train_iterator)\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)  # Reset the iterator\n",
        "            train_batch = next(train_iterator)\n",
        "\n",
        "        train_batch = tuple(b.to(device) for b in train_batch)\n",
        "        inputs = {'input_ids': train_batch[0], 'attention_mask': train_batch[1], 'Labels': train_batch[2]}\n",
        "\n",
        "        # Train the student on the labeled data (supervised loss)\n",
        "        outputs_student = student_model(**inputs)\n",
        "        loss_supervised = outputs_student.loss\n",
        "\n",
        "        # Get the corresponding unlabeled batch\n",
        "        try:\n",
        "            unlabeled_batch = next(unlabeled_iterator)\n",
        "        except StopIteration:\n",
        "            unlabeled_iterator = iter(unlabeled_loader)  # Reset the iterator\n",
        "            unlabeled_batch = next(unlabeled_iterator)\n",
        "\n",
        "        unlabeled_batch = tuple(b.to(device) for b in unlabeled_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits_teacher1 = teacher_model1(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            logits_teacher2 = teacher_model2(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            logits_teacher3 = teacher_model3(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1]).logits\n",
        "            ensemble_logits = (logits_teacher1 + logits_teacher2 + logits_teacher3) / 3\n",
        "\n",
        "            # Compute uncertainty\n",
        "            uncertainty = compute_uncertainty(logits_teacher1, logits_teacher2, logits_teacher3)\n",
        "            uncertainty_weight = 1 / (1 + uncertainty)\n",
        "\n",
        "        # Student model predictions on unlabeled data\n",
        "        outputs_student_unlabeled = student_model(input_ids=unlabeled_batch[0], attention_mask=unlabeled_batch[1])\n",
        "        loss_consistency = F.mse_loss(outputs_student_unlabeled.logits, ensemble_logits) * uncertainty_weight.mean()\n",
        "\n",
        "        # Total loss\n",
        "        loss = loss_supervised + loss_consistency\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Cyclic teacher update based on the epoch number\n",
        "        if epoch % 3 == 1:\n",
        "            alpha1 = calculate_alpha1(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha2 = calculate_alpha2(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model1, student_model, alpha1)\n",
        "            update_teacher(teacher_model2, student_model, alpha2)\n",
        "        elif epoch % 3 == 2:\n",
        "            alpha2 = calculate_alpha2(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha3 = calculate_alpha3(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model2, student_model, alpha2)\n",
        "            update_teacher(teacher_model3, student_model, alpha3)\n",
        "        elif epoch % 3 == 0:\n",
        "            alpha1 = calculate_alpha1(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            alpha3 = calculate_alpha3(epoch - (epoch / 3), (epochs * (2)) / 3)\n",
        "            update_teacher(teacher_model3, student_model, alpha3)\n",
        "            update_teacher(teacher_model1, student_model, alpha1)\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f'\\nEpoch {epoch}: Loss: {loss_train_total / (max_batches * 8):.3f}')  # Total loss normalized by total batches\n",
        "\n",
        "    # Label pseudo-data using the teacher models after every epoch and append to labeled data\n",
        "    if epoch % 1 == 0:\n",
        "        pseudo_labels, pseudo_confidence = label_pseudo_data(teacher_model1, teacher_model2, teacher_model3, dataset_unlabeled, confidence_threshold=0.95)\n",
        "\n",
        "        # Select only pseudo-labeled examples where confidence exceeds threshold\n",
        "        if len(pseudo_labels) > 0:\n",
        "            num_pseudo_labels = (pseudo_confidence >= 0.95).sum().item()\n",
        "            input_ids_unlabeled, attention_masks_unlabeled = dataset_unlabeled.tensors[0], dataset_unlabeled.tensors[1]\n",
        "            pseudo_confidence = pseudo_confidence.cpu()\n",
        "\n",
        "            # Select pseudo-labeled data based on confidence threshold\n",
        "            input_ids_pseudo = input_ids_unlabeled[pseudo_confidence >= 0.95]\n",
        "            attention_masks_pseudo = attention_masks_unlabeled[pseudo_confidence >= 0.95]\n",
        "            labels_pseudo = pseudo_labels[pseudo_confidence >= 0.95]\n",
        "\n",
        "            # Remove pseudo-labeled data from the unlabeled dataset\n",
        "            mask = pseudo_confidence < 0.95\n",
        "            num_removed_from_unlabeled = (pseudo_confidence >= 0.95).sum().item()\n",
        "            dataset_unlabeled = TensorDataset(input_ids_unlabeled[mask], attention_masks_unlabeled[mask])\n",
        "\n",
        "            # Update the training dataset with pseudo-labeled data\n",
        "            input_ids_combined = torch.cat((input_ids_train.to(device), input_ids_pseudo.to(device)), dim=0)\n",
        "            attention_masks_combined = torch.cat((attention_masks_train.to(device), attention_masks_pseudo.to(device)), dim=0)\n",
        "            labels_combined = torch.cat((labels_train.to(device), labels_pseudo.to(device)), dim=0)\n",
        "\n",
        "            # Create a new training dataset with both real labels and pseudo-labels\n",
        "            dataset_train = TensorDataset(input_ids_combined, attention_masks_combined, labels_combined)\n",
        "\n",
        "            # Update input_ids_train and attention_masks_train for future iterations\n",
        "            input_ids_train = input_ids_combined\n",
        "            attention_masks_train = attention_masks_combined\n",
        "            labels_train = labels_combined\n",
        "\n",
        "            print(f'Pseudo-labeling completed for epoch {epoch}.')\n",
        "            print(f'Number of pseudo-labels added: {num_pseudo_labels}')\n",
        "            print(f'Combined training set now has {len(dataset_train)} examples.')\n",
        "            print(f'Number of unlabeled samples removed: {num_removed_from_unlabeled}')\n",
        "            print(f'Combined unlabeled set now has {len(dataset_unlabeled)} examples.')\n",
        "        else:\n",
        "            print(f'No pseudo-labels above the threshold for epoch {epoch}.')\n",
        "\n",
        "\n",
        "\n",
        "      # Validation loop\n",
        "    student_model.eval()\n",
        "    teacher_model1.eval()\n",
        "    teacher_model2.eval()\n",
        "    teacher_model3.eval()\n",
        "    loss_val_total = 0\n",
        "    predictions_student, predictions_teacher1, predictions_teacher2, predictions_teacher3, true_vals = [], [], [], [], []\n",
        "\n",
        "    progress_bar_val = tqdm(DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=8),\n",
        "                            desc=f'Validation Epoch {epoch}', leave=False)\n",
        "\n",
        "    for batch in progress_bar_val:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            # Student model predictions\n",
        "            outputs_student = student_model(input_ids=batch[0], attention_mask=batch[1])\n",
        "            logits_student = outputs_student.logits\n",
        "            loss_val = F.cross_entropy(logits_student, batch[2])\n",
        "            loss_val_total += loss_val.item()\n",
        "\n",
        "            # Teacher model predictions\n",
        "            logits_teacher1 = teacher_model1(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits_teacher2 = teacher_model2(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "            logits_teacher3 = teacher_model3(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "\n",
        "            # Collect predictions and true labels\n",
        "            predictions_student.append(logits_student.detach().cpu().numpy())\n",
        "            predictions_teacher1.append(logits_teacher1.detach().cpu().numpy())\n",
        "            predictions_teacher2.append(logits_teacher2.detach().cpu().numpy())\n",
        "            predictions_teacher3.append(logits_teacher3.detach().cpu().numpy())\n",
        "            true_vals.append(batch[2].cpu().numpy())\n",
        "\n",
        "        progress_bar_val.set_postfix({'validation_loss': f'{loss_val.item():.3f}'})\n",
        "\n",
        "    # Concatenate predictions and true labels\n",
        "    predictions_student = np.concatenate(predictions_student, axis=0)\n",
        "    predictions_teacher1 = np.concatenate(predictions_teacher1, axis=0)\n",
        "    predictions_teacher2 = np.concatenate(predictions_teacher2, axis=0)\n",
        "    predictions_teacher3 = np.concatenate(predictions_teacher3, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    # Compute metrics for student and teacher models\n",
        "    metrics_student = compute_metrics(predictions_student, true_vals)\n",
        "    metrics_teacher1 = compute_metrics(predictions_teacher1, true_vals)\n",
        "    metrics_teacher2 = compute_metrics(predictions_teacher2, true_vals)\n",
        "    metrics_teacher3 = compute_metrics(predictions_teacher3, true_vals)\n",
        "\n",
        "    # Print validation metrics\n",
        "    print(f'Epoch {epoch}: Validation Loss: {loss_val_total / len(dataset_test):.3f}')\n",
        "    print(f'Student Model - Accuracy: {metrics_student[0]:.3f}, F1 Score: {metrics_student[1]:.3f}, Precision: {metrics_student[2]:.3f}, Recall: {metrics_student[3]:.3f}')\n",
        "    print(f'Teacher Model 1 - Accuracy: {metrics_teacher1[0]:.3f}, F1 Score: {metrics_teacher1[1]:.3f}, Precision: {metrics_teacher1[2]:.3f}, Recall: {metrics_teacher1[3]:.3f}')\n",
        "    print(f'Teacher Model 2 - Accuracy: {metrics_teacher2[0]:.3f}, F1 Score: {metrics_teacher2[1]:.3f}, Precision: {metrics_teacher2[2]:.3f}, Recall: {metrics_teacher2[3]:.3f}')\n",
        "    print(f'Teacher Model 3 - Accuracy: {metrics_teacher3[0]:.3f}, F1 Score: {metrics_teacher3[1]:.3f}, Precision: {metrics_teacher3[2]:.3f}, Recall: {metrics_teacher3[3]:.3f}')\n"
      ],
      "metadata": {
        "id": "8Ten7_2uLGZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "student_model.eval()\n",
        "teacher_model1.eval()\n",
        "teacher_model2.eval()\n",
        "teacher_model3.eval()\n",
        "loss_test_total = 0\n",
        "predictions_student, predictions_ensemble, true_vals = [], [], []\n",
        "\n",
        "# Use tqdm for the testing loop\n",
        "progress_bar_test = tqdm(DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=8),\n",
        "                         desc='Testing',\n",
        "                         leave=False,\n",
        "                         disable=False)\n",
        "\n",
        "for batch in progress_bar_test:\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "    with torch.no_grad():\n",
        "        # Student model predictions\n",
        "        outputs_student = student_model(input_ids=batch[0], attention_mask=batch[1])\n",
        "        logits_student = outputs_student.logits\n",
        "        loss_test = F.cross_entropy(logits_student, batch[2])\n",
        "        loss_test_total += loss_test.item()\n",
        "\n",
        "        # Teacher model predictions\n",
        "        logits_teacher1 = teacher_model1(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "        logits_teacher2 = teacher_model2(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "        logits_teacher3 = teacher_model3(input_ids=batch[0], attention_mask=batch[1]).logits\n",
        "\n",
        "        # Ensemble predictions (average of teacher logits)\n",
        "        logits_ensemble = (logits_teacher1 + logits_teacher2 + logits_teacher3) / 3\n",
        "\n",
        "        # Collect predictions and true labels\n",
        "        predictions_student.append(logits_student.detach().cpu().numpy())\n",
        "        predictions_ensemble.append(logits_ensemble.detach().cpu().numpy())\n",
        "        true_vals.append(batch[2].cpu().numpy())\n",
        "\n",
        "    # Update the progress bar with the current test loss\n",
        "    progress_bar_test.set_postfix({'test_loss': f'{loss_test.item():.3f}'})\n",
        "\n",
        "# Concatenate predictions and true labels\n",
        "predictions_student = np.concatenate(predictions_student, axis=0)\n",
        "predictions_ensemble = np.concatenate(predictions_ensemble, axis=0)\n",
        "true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "# Compute metrics for student model\n",
        "accuracy_student, f1_student, precision_student, recall_student = compute_metrics(predictions_student, true_vals)\n",
        "\n",
        "# Compute metrics for ensemble of teacher models\n",
        "accuracy_ensemble, f1_ensemble, precision_ensemble, recall_ensemble = compute_metrics(predictions_ensemble, true_vals)\n",
        "\n",
        "# Print testing metrics for student and ensembled teacher models\n",
        "print(f'Test Loss: {loss_test_total / len(dataset_test):.3f}')\n",
        "print(f'Student Model - Accuracy: {accuracy_student:.3f}, F1 Score: {f1_student:.3f}, Precision: {precision_student:.3f}, Recall: {recall_student:.3f}')\n",
        "print(f'Ensembled Teacher Models - Accuracy: {accuracy_ensemble:.3f}, F1 Score: {f1_ensemble:.3f}, Precision: {precision_ensemble:.3f}, Recall: {recall_ensemble:.3f}')\n"
      ],
      "metadata": {
        "id": "wfPhYjB2LPQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- LIME explainability with average of both student models ----\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer  # LIME Import\n",
        "# LIME for explainability: explain the output using the average of both student models\n",
        "class_names = list(label_dict.keys())\n",
        "explainer = LimeTextExplainer(class_names=class_names, split_expression='\\s+')\n",
        "\n",
        "def predict_average_students(texts):\n",
        "    encodings = tokenizer.batch_encode_plus(texts, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through both student models\n",
        "        outputs_student1 = teacher_model1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs_student2 = teacher_model2(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        outputs_student3 = teacher_model3(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Average the logits of both student models\n",
        "        avg_logits = (outputs_student1.logits + outputs_student2.logits+outputs_student3.logits ) / 3.0\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        probs = F.softmax(avg_logits, dim=1).detach().cpu().numpy()\n",
        "\n",
        "    return probs\n",
        "\n",
        "# Explain a random sample from the test set\n",
        "random_idx = random.randint(0, len(df_test) - 1)\n",
        "text_sample = df_test.iloc[random_idx][tweets_column]\n",
        "true_label = df_test.iloc[random_idx][labels_column]\n",
        "print(f\"Sample text: {text_sample}\")\n",
        "print(f\"True label: {class_names[true_label]}\")\n",
        "\n",
        "# Use the new prediction function for LIME\n",
        "exp = explainer.explain_instance(text_sample, predict_average_students, num_features=10,num_samples=100)\n",
        "exp.show_in_notebook()"
      ],
      "metadata": {
        "id": "dpRNR2GQLpJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}