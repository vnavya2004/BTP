* xlm roberta-japaneese,korean ---velpurunavya@gmail.com
* xlm roberta-arabic,bangla ---velpurunavya@gmail.com
* xlm roberta-spanish ---mnop20241@gmail.com
* multilingual-bangla ---gfg882004@gmail.com
* multilingual-arabic ---bvcxz20233@gmail.com
* multilingual-korean ---bvcxz20234@gmail.com
* multilingual-japaneese ---bvcxz20236@gmail.com
* multilingual-spanish  ---mnop20242@gmail.com

* LLAMA2(MULTILINGUAL)-bangla,japaneese ---gfg882004@gmail.com
* LLAMA2(MULTILINGUAL)-arabic,korean ---bvcxz20234@gmail.com
* LLAMA2(MULTILINGUAL)-spanish ---bvcxz20235@gmail.com
* LLAMA2(XLMROBERTA)-bangla,spanish --bvcxz20232@gmail.com
* LLAMA2(XLMROBERTA)-korean,japaneese ---bvcxz20233@gmail.com
* LLAMA2(XLMROBERTA)-arabic ---gfg882004@gmail.com


Results:
BASIC MODELS					
Dataset                  Model Used          Test Accuracy    Test precision   Test Recall    Test F1 score
* Arabic Dataset n      Multi-lingual BERT   0.9684 0.965791567 0.9712 0.968488233
* Bangla Dataset n      Multi-lingual BERT   0.828396323 0.68055555 0.597560976 0.636363636
* Japaneese Dataset n   Multi-lingual BERT	1	1	1	1
* Korean Dataset n      Multi-lingual BERT	1	1	1	1
* Spanish Dataset n     Multi-lingual BERT	0.93	0.927	0.939	0.933
* Arabic Dataset n      XLM_ROBERTA	      0.9724	0.991673605	0.9528	0.971848225
* Bangla Dataset n      XLM_ROBERTA	      0.81818	0.671717172	0.540650407	0.6
* Japaneese Dataset n	XLM_ROBERTA	       0.97	0.943	1	0.970873786
* Korean Dataset n	XLM_ROBERTA	      0.94	0.989	0.9	0.942
* Spanish Dataset n     XLM_ROBERTA          0.933	0.917	0.958	0.937
					
					
PREPROCESSING USING LLAMA2					
Datasets	        Model Used	Test Accuracy	Test precision	Test Recall	Test F1 score
* Arabic Dataset n	Multi-lingual BERT	0.9616	0.945904173	0.9792	0.962264151
* Bangla Dataset n	Multi-lingual BERT	0.774259448	0.780243061	0.774259448	0.771513741
* Japaneese Dataset n	Multi-lingual BERT	0.992	0.984251969	0.99	0.992063492
* Korean Dataset n	Multi-lingual BERT	0.984	0.968992248	0.99	0.984251969
* Spanish Dataset n	Multi-lingual BERT	0.907631954	0.936045087	0.88099631	0.907686824
* Arabic Dataset n	XLM ROBERTA	0.9644	0.955294118	0.9744	0.964752475
* Bangla Dataset n	XLM ROBERTA	0.748723187	0.96386334	0.748723187	0.660364646
* Japaneese Dataset n	XLM ROBERTA	0.736	0.697986577	0.832	0.759124088
* Korean Dataset n        XLM ROBERTA	0.968	0.946564885	0.992	0.96875
* Spanish Dataset n	XLM ROBERTA	0.86	0.819	0.94	0.87
